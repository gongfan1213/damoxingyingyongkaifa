### 前言
以ChatGPT为代表的大型语言模型（简称大模型）首次实现了基于语言的智能涌现，推动了通用人工智能的技术飞跃和快速进化，大模型已成为人工智能领域的热门发展方向，引起了国内外的广泛关注，成为全球科技竞争的焦点。

大模型技术通过强大的数据处理能力和广泛的适用性，极大地提升了生产力，改变了生产要素的构成。一方面，它加速了信息处理的速度和精度，使得数据成为新的生产资料，提高了知识创造和应用的效率；另一方面，通过促进跨领域知识融合和技术迭代，大模型技术增强了劳动者的技能和创新能力，同时催生了新的商业模式和服务形态，从而推动了社会经济活动的整体智能化和数字化转型。此外，大模型技术还通过提升自动化水平、优化资源配置、促进个性化服务和强化决策支持，进一步释放了生产潜能，推动了经济增长和社会进步。

#### 为什么要写这本书




当前，从国家到地方都在制定大模型的鼓励政策，大模型技术发展得如火如荼。各AI（人工智能）相关的企业、科研院所及高校迅速组建技术团队研发大模型应用产品，以参与到最新一轮的科技变革当中。

本书写作的初衷是更好地帮助大模型领域的相关技术人员，让他们跟上时代的步伐，尽快跨越从核心技术原理到领域实践的鸿沟。掌握这些技术不仅能够帮助他们解决更为复杂的问题，提高开发效率，还能帮助他们参与到跨领域和传统行业的数字化转型项目中，为职业生涯开辟更广阔的空间，进而利用大模型强大的数据处理能力，推动产业升级。

在本书的写作过程中，大模型技术也在不断变化。秉承大道至简的原则，笔者一方面尽可能在大模型原理和技术章节统筹各种概念，另一方面尽可能在领域应用章节跳出概念进行应用实践。笔者希望能抛砖引玉，以个人的一些想法和见解，为读者拓展出更深入、更全面的思路去解决业务问题。

### 本书特色
1. 本书基于中国科学技术大学（以下简称中国科大）研究团队在大模型方面的技术积累，结合科大讯飞实验室产品部在大模型方面的应用实践经验编写而成，涉及多个领域的开发实践，方便读者触类旁通，掌握一手的大模型应用开发技术。

2. 为了让读者轻松入门，本书将大模型的核心技术和技术拓展分开讲解，并屏蔽了一些复杂的底层技术，让读者先打通原理层面，再结合实践入门，为后续的深入学习打下基础，避免因细节问题而停滞不前。当然，为了让初级甚至无AI基础的读者能看懂基本原理，在一些AI术语第一次出现时给出简单的介绍，既有良好的可读性与一定的深度，也兼顾了整体内容推进的合理性。 

3. 为了让读者快速掌握大模型应用开发技术，本书详细解释了大模型开发过程中多种技术的应用方式以及需要考虑的问题，帮助读者提前定位业务问题，为实现大模型应用的最佳效果打下坚实的基础。

### 读者对象
#### （1）应用开发工程师
本书深入浅出地讲解大模型的工作流程和技术原理，通过组合多种大模型行业应用方式及多个大模型领域的应用实践案例，缩小了传统应用开发人员与大模型应用开发人员之间的技术鸿沟，有助于传统应用开发工程师实现快速转型。
#### （2）算法工程师 
本书聚焦于核心技术原理，使算法工程师能够快速理解大模型的工作流程、Transformer模型结构、提示工程、模型微调技术等，并根据实际情况进行扩展学习，身临其境地“体验”各种场景，准确定位不同场景下的优化重点，通过不同场景的模型微调实践，快速适配合适的模型优化方法。 
#### （3）技术方案工程师 
本书围绕大模型的组合应用方式，通过精心编写每个实践案例的应用背景、环境构建、代码实现及部署评测，帮助技术方案工程师进行效果闭环验证，从而实现大模型应用的最佳效果，这对解决业务问题有很好的借鉴作用。 
#### （4）提示工程师 
本书围绕提示工程的设计开发流程，详细讲解各种提示技巧，帮助提示工程师通过设计、实验和优化输入（提示）来引导大模型输出特定结果。 

### 如何阅读本书
本书共10章，从逻辑上分为“基础知识”“原理与技术”“应用开发实践”三部分，从大模型概念引出大模型核心技术，再到多个行业实践案例与代码实现，层层推进，便于读者的系统学习与落地应用。
- **基础知识（第1章）**：介绍大模型定义、应用现状、存在的问题，以及多个维度的发展趋势。
- **原理与技术（第2章和第3章）**：详细讲解大模型的构建流程，Transformer模型，以及模型微调、对齐优化、提示工程等核心技术，之后介绍了推理优化、大模型训练、大模型评估、大模型部署等拓展技术。 
- **应用开发实践（第4～10章）**：详细讲解大模型插件应用开发、RAG（检索增强生成）实践，以及智能客服问答、学科知识问答、法律领域应用、医疗领域应用、智能助写平台等多领域的实践。
通过本书，读者不仅能深入理解大模型的工作流程和技术原理，还能加深对大模型应用场景的理解，准确定位不同场景下的优化重点，提高大模型应用开发能力，并提升解决业务问题的能力。

### 勘误和支持
由于笔者水平有限，撰写时间仓促，书中难免会出现一些不当之处，恳请读者批评指正。限于篇幅，本书提及的一些文件和代码（如第5～10章）只给出了关键信息，或直接引用了相关的代码文件，读者可以从GitHub上进行下载，下载路径为https://github.com/datadance/book-llm.git。同时，你也可以通过AI技术交流QQ群435263033，或者邮箱datadance@163.com联系我们。期待得到大家的反馈，让我们在大模型应用开发与领域实践的征程中互勉共进。

### 致谢
科大讯飞的于俊负责大模型概述、插件应用开发实践、RAG实践、智能客服问答实践等内容的编写，程礼磊负责学科知识问答实践、法律领域应用实践、医疗领域应用实践等内容的编写。中国科大的程明月副研究员负责大模型核心技术、技术拓展内容以及智能助写平台实践的编写。
感谢中国科大的研究生张征、杨纪千，以及科大讯飞的张志勇、王文辉、陶柘、汪得志、陈迁、丁可、张伟等技术专家，在本书编写遇到困难的时候，他们一直给予我们鼓励和支持，并提供了宝贵的意见，使本书的质量更上一层楼。
本书参考了科大讯飞星火发布会的资料以及部分星火开源大模型的代码和数据，并使用了智谱AI开源的ChatGLM3、GLM-4-9B-Chat等基础模型，以及LangChain框架、Langchain-Chatchat框架、网易QAnything框架、讯飞开放平台API、高德开放平台API、AutoGen工具、DeepSpeed工具等公开资料，在这里特别致谢。
最后，感谢我的家人，他们的激励给了我奋斗的信心和力量，他们的支持使得本书得以面世。
谨以此书献给平凡世界中默默努力的小伙伴，以及众多热爱大模型技术的朋友。
于俊
