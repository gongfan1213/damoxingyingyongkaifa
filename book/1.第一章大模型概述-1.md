### 第1章 大模型概述
以ChatGPT为代表的大型语言模型（Large Language Models, LLM）带来的智能涌现（Emergence），不仅推动了人工智能技术的显著进步，也加速了其发展。大模型技术已经成为AI（人工智能）领域的前沿热点，引起了全球范围内的广泛关注和讨论，成为科技竞争的关键领域。

#### 1.1 大模型的概念

大型语言模型简称大模型，是NLP的一个重要分支和应用。NLP（Natural Language Processing，自然语言处理），作为计算机科学和AI（人工智能）领域中的一个核心方向，专注于利用计算机技术来分析、理解和处理自然语言。NLP的核心任务是将计算机作为语言研究的强大工具，不仅在计算机的支持下对语言信息进行定量化研究，还致力于提供一种人与计算机之间能够共同使用的语言描述。这种描述不仅有助于机器更好地理解人类的语言，也为人类提供了一种与机器交流的方式。

NLP主要包含两部分：NLU（Natural Language Understanding，自然语言理解）和NLG（Natural Language Generation，自然语言生成）。NLU的目标是使计算机能够理解自然语言文本的含义，而NLG则致力于使计算机能够以自然语言的形式表达深层的意图和思想。

尽管NLU和NLG面临的挑战巨大，但随着技术的进步，已经有一些实用的系统被开发出来，并在某些领域实现了商品化和产业化。这些应用包括多语种数据库和专家系统的自然语言接口、机器翻译系统、全文信息检索系统和自动文摘系统等。然而，开发出通用的、高质量的自然语言处理系统，仍然是一个长期且具有挑战性的目标。

本质上，大模型是一种深度神经网络模型，通常由数十亿个权重或数千亿个参数组成。以ChatGPT为例，其当前模型由1750亿个浮点数参数构成，是一个高度复杂的对话式AI系统。

大模型主要通过自监督学习（Self-Supervised Learning）或半监督学习（Semi-Supervised Learning）进行训练，利用预训练任务从大规模的无监督数据中挖掘自身的监督信息（用于训练模型的数据，不仅包含输入特征，还包含对应的输出标签或结果）。通过这种方式，模型能够学习到对特定领域有价值的表征（模型将输入数据转换成数学上的向量形式，以方便计算和分析）。在海量信息的参数化全量记忆、任意任务的对话式理解、复杂逻辑的思维链推理、多角色多风格长文本生成、程序代码生成和输入图像的语义层理解等方面，大模型实现了显著的突破，体现了语言智能的“智能涌现”。

智能涌现是指当模型的规模和训练数据量达到一定水平时，模型会展现出一些新的、更高级的技能，这可以被看作一种“量变引起质变”的现象。实验已经证明，针对相对复杂任务的智能涌现对模型的大小（如100亿个参数）是有要求的。智能涌现的通用AI系统在广泛的自然语言任务中展现出卓越的性能。

如图1-1所示的具有多模态能力的“智能涌现”的通用AI系统，不仅改变了信息的分发和获取模式，还革新了内容生产方式，实现了全自然交互完成任务，提供了专家级的虚拟助手，颠覆了传统的手工编程方式，成为科研工作的加速器。这些进步为解决人类的基本需求带来了全新的机遇。


### 图1-1 大模型的“智能涌现”解决人类刚需
|智能涌现的通用人工智能系统|改变信息分发和获取模式|革新内容生产模式|全自然交互完成任务|
| ---- | ---- | ---- | ---- |
|文本生成、语言理解、知识问答、逻辑推理、数学能力、代码能力、多模态能力|实现专家级的虚拟助手|颠覆传统手工编程方式|成为科研工作的加速器|

![image](https://github.com/user-attachments/assets/84d0ca4c-0334-42a9-9dc5-913c8cae056a)



如图1-2所示，AI的发展经历了一个螺旋式上升的过程。自1956年达特茅斯会议上首次提出AI概念以来，AI技术经历了多个重要阶段。

1. 20世纪50～20世纪70年代：AI的早期发展阶段，研究方向集中在符号逻辑推理上。

2. 20世纪80年代至90年代：知识工程成为AI领域的主要研究方向，强调知识库的构建和应用，即引入专家系统。

3. 21世纪初～2020年：深度学习技术的兴起，极大地推动了AI在图像识别、语音识别等领域的应用。

4. 2020年至今：深度神经网络大模型的发展，使得AI从简单的预测推断向复杂的内容生成迈进，从专用任务向通用任务扩展，并逐步替代从低端重复性工作到高端脑力劳动的各种任务。


### 图1-2 AI的四次浪潮
|阶段|时间|主要内容|
| ---- | ---- | ---- |
|智能靠数学（第一次浪潮）|20世纪50～70年代|定理证明（符号逻辑、神经网络）|
|智能靠编程（第二次浪潮）|20世纪80～90年代|知识工程（专家系统、多层神经网络）|
|智能靠建模（第三次浪潮）|21世纪初～2020年|深度学习（深度神经网络、大数据、GPU、云计算）|
|智能靠涌现（第四次浪潮）|2020年至今|深度神经网络大模型（Transformer模型与预训练技术）|

![image](https://github.com/user-attachments/assets/733f3880-9e53-46df-8156-1319f90a7fc2)


这一演进不仅标志着AI技术的进步，也预示着我们可能正在接近通用AI。

大模型的智能涌现预示着机器将能够真正掌握并运用人类语言和知识，开启一种“类人”的自然语言交互式学习新范式。这种以语言智能为核心的突破，标志着机器智能进入了一个全新的发展阶段。

作为人工智能迈向通用智能的关键技术，大模型在“大数据、大算力和强算法”的支持下，通过在海量数据上进行预训练 ，以及提示工程（Prompt Engineering）或模型微调 （在有标注数据的特定领域任务上进行二次训练），能够完成多种应用场景的任务，展现出完成通用任务的潜力。

大模型的学习和发展过程与人类的成长过程有着惊人的相似之处。人类的成长需要广泛的阅读、丰富的实践和深入的交流，而大模型则需要大规模的数据输入、模型预训练和微调迭代。人类的基础教育和大学教育相当于大模型的预训练阶段，而研究生学习和职业学习则相当于大模型的微调迭代和强化领域技能。此外，大模型的模型对齐过程，实际上也是在模仿人类遵守法律和道德规范的过程。

大模型的预训练是一种深度学习技术，它的作用是让模型在大量文本数据上学习语言的通用特征和模式。通过这种方式，模型能够捕捉到语言的复杂性和多样性，为后续在特定任务上的微调打下基础。预训练的模型具备了较强的语言理解能力，能够有效地应用于各种NLP任务。

大模型微调技术是一种深度学习策略，通常在预训练的语言模型上应用。这种方法利用标记好的数据对模型进行微调，使其适应特定的任务或领域，从而提高准确性和泛化能力。



#### 1.2 大模型的应用现状

自深度学习及AlphaGo掀起科技浪潮后，我国的AI领域正经历新一轮的动荡，大模型与AIGC技术及其应用正在激发国内AI企业加速重构底层技术和应用框架。星火大模型、文心一言、通义千问等面向公众开放的举措，标志着我国AI大模型商业化进程的启动。全面开放的大模型将直面市场考验，通过用户反馈驱动自我进化，预计在不久的将来便可见证整个产业理念与应用层面的革新。本节将带领大家了解国内外主流的大模型。



##### 1.2.1 国外的大模型

国外大模型产业竞争激烈，主要企业包括OpenAI、Meta、Anthropic、Google等。

1. **GPT系列**

2018年，美国AI研究公司OpenAI提出了第一代GPT模型，将NLP带入“预训练”时代。随后，OpenAI沿着GPT的技术思路，陆续发布了GPT-2、GPT-3、ChatGPT、GPT-4等产品，以及使用GPT-3代码数据进行微调的编程大模型Codex、文生视频模型Sora。

    - **GPT-3**：2020年5月，OpenAI发布了GPT-3，它包含1750亿（175B ）个模型参数，可以通过少量的样本进行学习。和人类一样，GPT-3不需要看完所有样例才能学习，而是看一小部分样例就能学会更多的知识。
GPT-
3的体量非常庞大，因此在特定领域任务中进行调优（Fine-Tune）的成本很高。为了解决这个问题，GPT-3使用了语境学习（In-Context Learning，ICL）的方式，在不进行梯度更新或调优的情况下，直接在上下文中进行学习。它通过提供具体任务的“提示”，即便不对模型进行调整也可完成任务。如果在输入中提供一个或几个示例，那么任务完成的效果会更好。

提示：梯度更新是机器学习和深度学习中优化算法的核心组成部分，尤其是在训练神经网络时。在模型的训练过程中，我们定义一个损失函数（或称目标函数、代价函数），这个函数量化了模型预测值与实际值之间的差异。我们的目标是最小化这个损失函数。

梯度是损失函数关于模型参数的偏导数，它指向损失增加最快的方向。因此，负梯度则指向损失减少最快的方向。在训练过程中，我们通过计算损失函数关于每个参数的梯度，然后按照这个梯度的反方向更新参数来逐步减少损失。这个过程称为梯度下降，而每次根据梯度调整参数的过程就是梯度更新。
梯度更新通常遵循这样的公式：

\[ \theta_{new} = \theta_{old} - \eta \cdot \nabla J(\theta_{old}) \]

![image](https://github.com/user-attachments/assets/fada0f3e-4b99-4871-a507-329f8d8e0623)


其中，\(\theta_{old}\)是旧的参数值，\(\theta_{new}\)是更新后的参数值，\(\eta\)是学习率（决定了更新步长的大小），\(\nabla J(\theta_{old})\)是损失函数\(J\)在当前参数值下的梯度。通过反复执行这种梯度更新，模型参数会逐渐调整到使损失函数最小化的最优解附近。

这里的B代表10亿。——编辑注

GPT-3不仅在各种NLP任务中具有非常出色的性能，而且在一些需要推理或特殊领域任务中也表现得非常出色。GPT-3也被视为从PLM（预训练语言模型）到大模型发展过程中的一个重要里程碑。
    - **ChatGPT**：2022年11月30日，OpenAI发布了基于GPT模型的会话大模型ChatGPT，上线两个月活跃用户数过亿。从技术角度讲，ChatGPT是一个聚焦于对话生成的大模型，它能够根据用户的文本描述，结合历史对话，产生相应的智能回复。ChatGPT在与人类交流方面表现出优越的能力，开启了机器自然语言交互式学习的“类人”新范式。
    - **GPT-4**：2023年3月，OpenAI发布的GPT-4将大模型的输入扩展到多模态信息。GPT-4比ChatGPT具有更强的复杂任务解决能力，在许多评估任务上都有很大的性能提高。
值得注意的是，GPT-4在奖励模型上新增了一个安全奖励机制，用来减少有害信息的输出。相比ChatGPT，GPT-4进一步解决了ChatGPT面临的长文本输入、多模态输入、外部实时知识运用等诸多挑战，在复杂认知任务（跨学科语言理解、跨行业知识运用）、复杂推理任务、多模态任务等方面继续进步，进一步抬高了智能涌现的上限，再一次惊艳世人。

GPT-4模型在理解人类语言方面获得了里程碑式的成就。
    - **Codex**：Codex是基于GPT-3进行微调的编程大模型，是OpenAI将大模型技术应用于代码领域的重要案例。Codex的训练数据来自GitHub（约为159GB的代码数据）。基于Codex，GitHub与OpenAI合作推出另一个面向市场的代码补全工具Copilot，旨在帮助程序员编写代码。
    - **Sora**：2024年2月，OpenAI发布首个文生视频模型Sora，引爆全球。Sora以通用大模型为底座，效果显著超越业界现有视频模型的同类产品，更加体现出通用AI的潜力。Sora和业界视频模型的生成能力比较如表1-1所示。

### 表1-1 Sora和业界视频模型的生成能力比较

|视频模型|研发团队|推出时间|主要特点|视频长度/s|视频帧率/fps|视频分辨率/px|
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|Gen-2|Runway|2023年6月|基于Diffusion模型，利用文本、图像生成高保真和一致性良好的视频，画面清晰、精美，可生成4K画质视频|4～16|24|768×448、1536×896、4096×2160|
|Pika1.0|PIKA Labs|2023年11月|基于Diffusion模型，语义理解能力较强，画面一致性良好|3～7|8～24|1280×720、2560×1440|
|StableVideo Diffusion|Stability AI|2023年11月|开源模型，首个基于图像模型Stable Diffusion的生成式视频基础模型|2～4|3～30|576×1024|
|Emu Video|Meta|2023年11月|基于Diffusion模型，在生成质量和文本忠实度上表现较好|4|16|512×512|
|W.A.L.T|李飞飞团队与谷歌|2023年12月|基于Transformer+Diffusion架构，降低了计算和数据集的要求|3|8|512×896|
|Sora|OpenAI|2024年2月|Transformer+Diffusion，突破性的语义理解能力，以及复杂场景变化模拟能力|60|30|1080×1920、1920×1080|
|Pixeling|智象未来|2023年8月|基于文本生成关键帧，再进行时间维度的前后拓展|4～15|8|432×768、768×432|
|MiracleVision 4.0|美图|2024年1月|清晰度、连贯性等较好，处于国内第一梯队，已应用于电商和广告领域|3|16|960×1280、1280×1280、1280×720|
|PixVerse|爱诗科技|2024年1月|与Pika效果接近，能够处理较强的运动幅度，同时保持较好的一致性|4|18|576×1024、1024×768|

Sora能够生成分钟级时长的视频，支持单视频多镜头，且能更好地理解提示，如以“生成一段美丽的剪影动画，展现一只狼感到孤独，在月光下嚎叫，直到它找到自己的群体。”为例，生成的动画截图如图1-3所示。该图能够展示出月光、狼，还有孤独的感觉。

### 图1-3 Sora生成的动画截图
大模型文生视频技术并不是真正的物理世界的模拟器，而是物理3D视觉世界的逼真模拟，存在一些局限性。比如会出现吹不灭的蜡烛、悬空的椅子、人在铁轨上行走等情况，也不足以完全模拟所有现实中的物理过程（比如重力、摩擦力、流体动力学等）。另外，它还存在推理效率的问题，在同等参数量、数据量，训练时间比文生图模型要长2至3个量级。


2. **LLaMA系列**

2023年，Meta发布开放且高效的大语言模型LLaMA，有7B、13B、33B、65B（650亿）4种版本。

LLaMA的模型性能非常优异，在大多数基准测试上，130亿参数量的LLaMA模型可以胜过GPT-3（参数量达1750亿），而且可以在单块V100 GPU（图形处理器）上运行；而650亿参数量的LLaMA模型可以媲美Google的Chinchilla-70B和PaLM-540B。

LLaMA的训练集来源于公开数据集，无任何定制数据集，保证了其工作与开源兼容和可复现。其中，LLaMA-7B是在1万亿个Token上训练的，而LLaMA-33B和LLaMA-65B是在1.4万亿个Token上训练的。

2023年7月，Meta发布免费的商用开源模型LLaMA 2。LLaMA 2对LLaMA模型进行升级，预训练语料增加了40%，增至2万亿个Token，且训练数据中的文本来源更加多样化。LLaMA 2包括LLaMA 2预训练模型和LLaMA2-chat微调模型，有7B、13B和70B参数量的版本，覆盖了不同应用场景的需求。

其中，LLaMA2-chat微调模型是在超过100万条人工标注的数据下训练而成的。除了训练数据的增加，LLaMA 2的训练过程也有两个值得关注的点：一是扩大了上下文长度，提升了模型的理解能力；二是采用查询注意力机制，提高了模型的推理速度。

其他主流模型还有Anthropic的Claude系列、Google的PaLM系列及Gemini系列，读者可自行了解。



##### 1.2.2 国内的大模型
国内大模型正在经历从“百模大战”转向“主要玩家凸显”阶段。据统计，2023年

其他主流模型还有Anthropic的Claude系列、Google的PaLM系列及Gemini系列，读者可自行了解。

### 1.2.2 国内的大模型
国内大模型正在经历从“百模大战”转向“主要玩家凸显”阶段。据统计，2023年我国累计发布200余个大模型，主要包括讯飞星火、文心一言、通义千问、清华GLM、智谱清言，以及字节豆包、腾讯混元、华为盘古、月之暗面的kimi等。本节不会介绍全部大模型，读者可自行了解。

1. **讯飞星火**

2023年5月6日，科大讯飞发布讯飞星火大模型，经过持续迭代，先后推出V1.5、V2.0、V3.5、V4.0版本。讯飞星火大模型拥有跨领域的知识和语言理解能力，能够基于自然对话方式理解与执行任务。它能够利用海量数据和大规模知识持续进化，实现从提出、规划到解决问题的全流程闭环。

讯飞星火大模型拥有七大能力（见图1-4），包括多风格多任务长文本生成能力、多层次跨语种语言理解能力、泛领域开放式知识问答能力、情景式思维链逻辑推理能力、多题型步骤级数学能力、多功能多语言代码能力、多模态输入和表达能力。其中，语言理解、数学能力超越GPT-4 Turbo，代码能力达到GPT-4 Turbo的96%，多模态能力达到GPT-4V的91%。星火伙伴、智慧教育、星火App、讯飞晓医、星火教师助手、讯飞智作、智能编程助手iFlyCode、星火科研助手等AI应用，加速了行业产品的创新。



### 图1-4 讯飞星火七大能力及行业产品创新示例

|能力|星火3.0|星火3.5|
| ---- | ---- | ---- |
|文本生成| - | - |
|语言理解| - | - |
|知识问答| - | - |
|逻辑推理| - | - |
|数学能力| - | - |
|代码能力| - | - |
|多模态能力| - | - |

![image](https://github.com/user-attachments/assets/25051847-f8ee-4fc8-b1c2-182c65b83e6b)



2. **文心一言**

2023年3月，百度新一代大模型文心一言（ERNIEBot）正式启动邀测。2023年8月，文心一言向全社会全面开放。文心一言是在ERNIE及PLATO系列模型的基础上研发的新一代知识增强大模型，多轮对话表现出色，能够与人对话互动、回答问题、协助创作，高效便捷地帮助人们获取信息、知识和灵感。

文心一言对数万亿数据和数千亿条知识进行融合学习，得到预训练大模型，在此基础上利用有监督微调（SFT）、RLHF、提示工程等技术，具备了知识增强、检索增强和对话增强的优势。文心一言在文学创作、商业文案创作、数理推算、中文理解、多模态生成等使用场景中具有强大的综合能力。

2023年10月17日，百度发布文心大模型4.0，实现了基础模型的全面升级，它在理解、生成、逻辑和记忆能力上都有显著的提升，据悉综合能力“与GPT-4相比毫不逊色”。

3. **通义千问**

2023年4月，阿里推出通义千问大模型；2023年10月，阿里发布千亿级参数大模型通义千问2.0，在性能上取得巨大飞跃。

通义千问2.0在复杂指令理解、文学创作、通用数学、知识记忆、幻觉抵御等能力上均有显著提升。通义千问2.0在指令遵循、工具使用、精细化创作等方面进行了技术优化，能够更好地被下游应用场景集成。通义千问大模型官网上线了多模态和插件功能，支持图片输入、文档解析等细分任务。用户可以在官网上直接体验模型功能，开发者可以通过网页嵌入、API/SDK调用等方式，将模型能力集成到自己的大模型应用和服务中。

2024年5月，阿里云发布通义千问2.5版本，该版本在理解能力、逻辑能力、指令遵循和代码能力方面有了显著提升，经过权威基准OpenCompass评测，该模型的中文性能（比如文本理解、文本生成、知识问答等），全面赶超GPT-4 Turbo。

阿里云已与60多个行业头部企业进行深度合作，推动通义千问在办公、文旅、电力、政务、医保、交通、制造、金融、软件开发等领域的落地。

4. **清华GLM**

2022年5月，清华大学发布大模型GLM。GLM采用了wudao2.0中文语料，以及Wikipedia、BookCorpus等13GB英文语料。主要创新点是提出了自回归空白填充（Autoregressive Blank Infilling）的自监督训练方式，通过调整空白块的大小，GLM既可像Encoder - only模型一样执行文本分类等NLU任务，也可以像Decoder - only模型一样执行文本生成等NLG任务，还可以像Seq - to - Seq模型一样执行对话、机器翻译等条件NLG任务，通过一个预训练任务实现了预训练模型三个结构的统一。

ChatGLM - 6B是基于GLM架构的一个开源的、支持中英双语的对话语言模型，具有62亿个参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4量化级别下最低只需6GB显存）。

ChatGLM - 6B使用了和ChatGPT相似的技术，针对中文问答和对话进行了优化。经过约1T个标识符的中英双语训练，辅以监督微调、反馈自助、RLHF等技术，62亿个参数的ChatGLM - 6B已经能生成相当符合人类偏好的回答。

5. **智谱清言**

2023年8月，北京智谱华章科技有限公司发布“智谱清言”。智谱清言已具备“通用问答、多轮对话、创意写作、代码生成以及虚拟对话”等功能，未来还将开放多模态等生成能力。

智谱清言是基于智谱AI自主研发的中英双语对话模型ChatGLM2，经过万亿字符的文本与代码预训练，并采用SFT技术，以通用对话的形式为用户提供智能化服务。



### 1.2.3 大模型的应用情况

大模型已经在各个垂直领域中广泛落地。国内的大模型产业链可以分为基础层、模型层、平台层、应用层，每层都有主流厂家，如图1-5所示。

大模型的业务应用场景主要分为两大类：生成场景与决策场景。生成场景涵盖对话交互、虚拟顾问、创意内容创作、代码编写及智能代理等；决策场景则侧重于基于描述与诊断的辅助决策，以及预测导向的智能决策制定。如图1-6所示。

在设计业务场景时，应注重聚焦、颗粒化和可控。聚焦意味着让大模型专注于核心需求和关键问题，避免面面俱到；颗粒化是让大模型避免处理过于庞大和复杂的业务流程，防止过度延伸；可控则要求对大模型进行专业知识的限定，确保其行为符合预期。同时，加强大模型与垂直场景需求的匹配，推动其在各领域的广泛应用，是当前各业务线需要重视的问题。随着时间的推移，大模型在垂直行业的应用会变得更加深入和广泛，涵盖内容生成、智能客服、商业服务、智能办公、智慧教育、智慧医疗和互动陪伴等多个典型场景。

![image](https://github.com/user-attachments/assets/29530f2c-2250-4472-837f-459620854f83)


![image](https://github.com/user-attachments/assets/cc366e3c-be51-44b4-848c-4e2e6646fa4c)


### 图1-5 国内大模型产业链
|层次|代表企业|
| ---- | ---- |
|应用层|知乎、字节跳动、美团、爱奇艺等|
|平台层|百度、360、阿里、腾讯等|
|模型层|百度、阿里、腾讯、华为等|
|基础层|百度、阿里、腾讯、华为等|

### 图1-6 大模型的业务应用场景
|生成场景|对话式交互（通过自然语言与用户进行交互，典型场景：聊天机器人）、虚拟专家（在特定领域，通过对大量的非结构化数据总结，为用户提供专业意见，典型场景：智能客服）、内容生成（生成用户需要的文字、图片、音频、视频、3D模型等，典型场景：AI绘画）、代码开发（对已有代码检查、修正，或根据要求生成代码，典型场景：代码生成）、智能体（通过对话，调用内外部数据，满足用户目标，短期内难以实现，典型场景：Auto - GPT）|
| ---- | ---- |
|决策场景|描述（通过数据采集和展示，描述业务正在发生什么，实现业务可视化，典型场景：数据大屏）、辅助决策（通过数据分析发现业务现象背后的原因，实现业务可诊断，典型场景：数据分析）、预测（通过数据分析，判断业务未来可能会发生什么，实现业务结果可预测，典型场景：机器学习平台）、指导（通过数据分析建模，由系统直接给出能达成预期业务目标的行动方案，典型场景：智能决策系统）|

### 1.3 大模型存在的问题
大模型的发展如日中天，然而人们对大模型技术的掌控和认知仍处于初级阶段，大模型技术还存在不少问题与挑战，比如机器幻觉、安全伦理、选择错误目标、难以监督等。

#### 1.3.1 机器幻觉
大模型尽管取得了显著的成功，但偶尔会产生看似合理但与用户输入、先前生成的上下文或事实知识偏离的输出，这种现象被称为机器幻觉。在大模型出现之前，幻觉已经在NLG领域广泛出现，通常指生成与提供的源内容毫无关联或不正确的内容。这个定义已经被扩展到大模型领域。

1. **大模型幻觉的分类**

大模型背景下的幻觉大致可分为三类：
    - 输入冲突幻觉，即大模型生成与用户提供的源输入不符的内容。
    - 上下文冲突幻觉，即大模型生成与其自身先前生成的信息冲突的内容。 
    - 事实冲突幻觉，即大模型生成不符合已建立的现实世界知识的内容。 

2. **大模型幻觉的主要来源**

综合分析大模型的生命周期不同阶段的特点，可以得出大模型幻觉的主要来源。
    - 大模型缺乏相关知识或内化了错误的知识。在预训练阶段，大模型从大量的训练数据中积累了大量知识，这些知识存储在模型参数中。当要求回答问题或完成任务时，如果大模型缺乏相关知识或已经内化了来自训练语料库的错误知识，它通常会表现出幻觉。例如，研究发现大模型有时会误解偶然的相关性，比如位置接近或高度共现的关联，将其视为事实知识。此外，人类生成的语料库中也存在幻觉（如过时、有偏见或虚构的表达），大模型容易复制甚至放大这种幻觉行为。
    - 大模型有时会高估自己的能力。研究发现，大模型的正确和错误答案的分布熵可能相似，这表明大模型在生成不正确的答案时与生成正确答案一样自信。这种过度自信可能导致大模型以不必要的确定性制造答案。
    - 问题对齐过程可能诱发大模型幻觉。大模型预训练后会进行对齐，在这个过程中大模型会进一步训练，以使其响应与人类偏好一致。然而，当大模型在对齐过程中接受在预训练阶段尚未获得的知识的指示时，实际上就是一种不对齐的过程，会“鼓励”大模型产生幻觉。此外，有时大模型可能会生成有利于用户观点而不是正确或真实答案的响应，这也可能导致幻觉。 
    - 大模型采用的生成策略存在潜在风险。大模型以顺序方式生成响应，一次输出一个Token。研究发现，大模型有时会过分坚持早期的幻觉，即使它意识到这是不正确的。换句话说，大模型可能更喜欢为了自身一致性而堆积幻觉，而不是从错误中恢复。这被称为幻觉堆积现象。此外，一些研究强调，基于采样的生成策略（如top - p和top - k）引入的随机性也可能是幻觉的潜在来源。 

3. **危害与挑战**

幻觉严重损害了大模型在现实世界场景中的可靠性。例如，大模型有可能制造出错误的医学诊断或导致实际生活风险的治疗计划。虽然传统的NLG环境中的幻觉问题已经得到广泛研究，但理解和解决大模型领域的幻觉问题仍面临着独特的挑战。

与为特定领域任务精心策划数据不同，大模型的预训练使用来自网络的数万亿个Token，难以消除虚构、过时或有偏见的信息。通用大模型在跨任务、跨语言和跨领域设置中表现出色，但这为全面评估和缓解幻觉问题带来了挑战。大模型可能生成最初看似高度合理的虚假信息，这使得模型甚至人类难以检测幻觉。 

4. **解决策略**

要解决AI大模型的幻觉问题，需要采取一系列的策略。

首先，需要在模型的训练阶段引入更多的数据，以减少模型对特定数据模式的过度拟合；其次，使用更强大的模型架构和优化算法，以提高模型的泛化能力和鲁棒性；最后，对模型的输出进行适当的后处理和验证。

除了这些技术性的解决方案外，也需要从设计和伦理的角度来解决幻觉问题。例如，应该考虑如何设计出更加透明和可解释的大模型，以便用户能够理解模型的运作方式和输出结果。此外，还需要制定相应的伦理规范和法规，以确保AI大模型的应用不会对人类或其他生物造成负面影响。

总之，AI大模型的幻觉问题是一个复杂的问题，需要采取多种策略和技术来解决。大模型的知识记忆是模糊的，同时缺少判断知识有效性的机制，所以需要外部知识增强。通过不断研究和实践，相信人们能够更好地解决这个问题，从而使AI大模型在各个领域发挥更大的作用，为人类社会带来更多的便利。



#### 1.3.2 安全伦理

在数字化时代，大模型技术作为人工智能的关键力量，正深刻地重塑着各行各业。然而，伴随着大模型带来的巨大益处，大模型的安全伦理问题仿佛是高悬在头顶的“达摩克利斯之剑”，时刻提醒着人们大模型时代的机遇也伴随着风险。

数据泄露和隐私侵犯是大模型面临的重要安全伦理问题。由于大模型依赖大量数据进行训练，这些数据中不乏敏感信息。一旦管理不当造成泄露，轻则侵犯用户隐私，重则造成严重的信息安全事件。此外，数据泄露的风险随着数据量的增加而呈指数级上升，这对数据保护机制提出了更高的要求。

算法偏见也是一个不容忽视的问题。大模型的训练数据往往来自现实世界，而这些数据可能包含了历史偏见和歧视。如果技术团队在设计和训练模型时没有进行适当的干预，大模型输出的结果可能会重现有害的社会偏见，加剧社会不平等，违背道德伦理。 

随着大模型的增大，它在问答任务和需要提供事实答案的任务上表现得更好，但在确保输出内容的真实性方面仍存在不稳定性。在需要常识和逻辑推理的领域，以及给语言模型提供有关常见误解的信息时，这种问题尤为显著。语言模型的不真实信息是指模型输出虚假、误导性、无意义或质量低劣的错误信息。这些错误信息的生成机制在一定程度上与大模型的基础结构相关。大模型可以被训练来输出语句，句子中可能包含与事实不符的陈述，如过时的信息、虚构的作品和故意的虚假信息。即使经过训练的大模型能“忠实”地反映这些数据，也可能会再次产生类似的错误陈述。然而，即使训练数据全由正确陈述构成，也无法完全避免错误信息的产生，因为模型可能无法完全理解训练数据背后的因果关系。因此，使用训练好的语言模型进行预测时可能会产生错误信息，进而带来多种问题，包括无意中误导或欺骗他人，造成实际伤害，以及加剧公众对共享信息的不信任。 

大模型的“黑箱”特性导致了可解释性问题。由于模型结构复杂，其决策过程往往难以被用户理解。这种不透明性不仅降低了用户对模型的信任，更可能在关键时刻导致错误的决策，涉及生命与财产安全的领域尤其不能忽视这一问题。 

此外，大模型可能在无意中造成歧视。例如，在招聘、贷款审批等场景下，大模型可能会基于不经意的关联性，对某些群体产生不利的决策。大模型应用中的责任归属与道德风险也是一个复杂问题。以自动驾驶汽车为例，一旦发生事故，确定责任主体并不容易。这不仅需要技术创新，还需要法律、伦理的共同进步，以明确各种情况下的责任归属问题。 

要解决以上安全伦理相关的问题，需要多方参与和协作。政府需出台相关法律法规，引导和规范大模型的开发与应用。企业和研究机构应担负起社会责任。公众应增强自我防护意识，并积极参与到科技伦理的讨论中来。只有通过集体的努力，才能确保大模型技术的健康发展，使其成为推动社会进步的力量。

在未来，随着大模型应用的不断深入，其安全伦理问题也将更加复杂多变。我们必须不断提高警惕，加强研究，确保大模型技术的健康发展。



#### 1.3.3 选择错误目标

在选择目标时，人们可能无意中或出于恶意选择了错误的方向。要从人群中挑选出具有代表性并能提供高质量反馈的个体是困难的。实施大规模RLHF（基于人类反馈的强化学习）时，需要精心挑选和指导参与的人类评估者，但这可能导致样本偏差问题。

研究指出，在应用RLHF后，大模型在政治倾向上会系统性地偏离中立。尽管这种偏见的确切原因尚不清楚，但数据收集过程表明评估者的选择与研究员的判断相一致，这暗示了在偏好数据收集过程中存在明显的选择效应。不同大模型所招募的评估者的构成与一般人口结构存在差异。例如，OpenAI报告其初始的评估者群体中约50%来自菲律宾和孟加拉国，年龄为25～34岁，而Anthropic则称其评估者中有68%为白人。这些评估者的人口统计特征可能会带来难以预测的潜在偏见，进而在模型训练过程中被放大。

一些评估者会持有有害的偏见



![image](https://github.com/user-attachments/assets/36a98c76-6adf-41e2-b67d-05a24fe3b963)

2023年，Meta发布开放且高效的大语言模型LLaMA，有7B、13B、33B、65B（650亿）4种版本。
