#### 1.3.4 难以监督

对AI进行有效监督是困难的。受限于人类有限的注意力和能力，反馈往往不可避免地带有某种偏见，这使得建模过程复杂化。这种困难源于人类的不完美性，导致在监督高级的AI系统时无法面面俱到。

人类错误可能由多种因素引起，包括缺乏对任务的兴趣、注意力分散、时间限制或固有的人类偏见等，这些因素都可能导致认知偏见和常见误解，从而影响反馈的质量。随着大模型的能力日益增强，人类评估者愈发倾向于将任务外包给聊天机器人，这种做法破坏了人类监督的初衷。

即使在拥有充足的信息和时间的情况下，人类在评估复杂任务时也可能提供低质量的反馈。将RLHF应用于超出人类控制能力范围的模型时，这个问题会变得更加明显。

依靠单一奖励模型来代表多元化的人类社会是存在缺陷的。RLHF通常被设计为让AI系统与个人偏好对齐的解决方案，然而人们在偏好、专业知识和能力方面的差异很大，评估者之间也常常存在分歧。如果忽视了这些差异，试图将来自不同人的反馈简化为单一奖励模型，可能会导致出现根本性的错误。目前的技术将评估者之间的差异视为噪声而非重要的分歧，这可能在偏好不一致时导致多数意见占优势，从而可能会对少数代表性群体造成不利影响。

综上所述，大模型技术是把双刃剑，我们需要正视以ChatGPT为代表的大模型技术带来的机遇与挑战，并谨慎应对。当前面临的挑战并不预示着大模型的终结，相反，人们对这些困境和局限性的深入了解，会为大模型未来的发展奠定基础。大模型仍然有巨大的潜力，等待我们去探索。



### 1.4 大模型的发展趋势

随着大模型技术的成熟、推理能力和准确性的提高，深度赋能业务已经成为大模型发展的重心，主要体现为以下几个趋势。



#### 1.4.1 多模态能力

多模态是指结合了文本、图像、语音、视频等多种数据形式的模型。OpenAI发布的GPT - 4V，不仅仅可以通过文字来对话，还可以通过语音和图片进行沟通。文生视频模型Sora充分利用GPT - 4V多模态认知模型为视频训练标注的高质量数据，能够生成分钟级时长的视频。尤其是Sora对物理规律的模仿，已经具备了一定程度的世界模拟器能力，有望向世界模型进化。Google发布的多模态大模型Gemini，无缝跨域文本、图像、音频和视频，可实现对超长文本的处理以及对长时音视频的理解，进一步丰富了应用场景。

多模态技术的持续进步，在丰富用户多维和沉浸式体验、提高多模态数据处理效率、理解复杂的现实世界场景、创新各种新产品形态和新服务形式等多方面，将产生巨大的价值。结合行业知识，多模态大模型有望应用于视频内容分析、语音识别结合文本理解、互动广告、交通态势感知、制造业产品研发设计、农业生产检测和优质育种等众多场景。



#### 1.4.2 AI Agent

AI Agent是一种能够感知环境、进行决策和执行动作的智能体。

尽管技术尚未成熟，但已有一些与工作流程深度耦合的AI Agent涌现。Copilot可以创建类似人类撰写的文本和其他内容，从而提高工作效率。Meta AI产品推动了内容创作和社交互动的智能化，为用户带来更加丰富多样的体验。工业视觉检查机器人的应用，显示了AI Agent在识别、判断和维修设备方面的高度自主性。SalesGPT等平台的出现，展示了AI Agent在感知情绪、个性化推广和客户服务中的潜力。

随着AI技术在深度学习和自主决策能力方面的突破，一个明显的趋势是AI正在从简单的工具进化为复杂的助手乃至Agent。一旦AI Agent能够准确理解复杂的任务需求、自主选择最合适的解决方案，并有效控制任务进度，就能推动各行各业的智能化转型，推动生产力的指数级增长。未来，AI Agent可能集成到组织机构的各个层面，与人类员工、其他数字化系统以及基础设施形成一个互联互通、高效运作的生态系统，进一步优化组织结构，提升运营效率，创造前所未有的价值。



#### 1.4.3 端侧应用

超过千亿参数的大模型层出不穷，从手机厂商到科技公司，各家都在不断强化自己的AI能力，大模型因其强大的能力和出色的表现而受到广泛关注。

需要注意的是，大模型正在向端侧转移，AI推理将在手机、PC、耳机、音响、XR设备、汽车，以及一系列可穿戴式新型终端上运行。端侧轻量化的“小模型”越来越受到关注，“小模型”不仅可以减少计算资源的消耗，还可以加快响应速度，因而在实时应用场景中的应用更为广泛，在资源受限的环境中表现出色。相比大模型，端侧“小模型”具有一些独特优势，如本地数据处理效率更高、节省云端服务带宽和算力成本，带来更好的用户数据隐私保护、更新的交互方式和体验等。

作为新技术应用的风向标，手机和汽车行业优先落地端侧大模型技术。

其中，手机端侧大模型应用包括手机AI助手和App内AI助手。手机AI助手在操作系统层面提供服务，能跨越多个应用程序并提供全面支持。用户可以通过语音、文本或其他输入方式与全局AI助手交互，以执行各种任务，如搜索信息、管理日程、发送消息、控制智能家居设备等，甚至可以调用各类手机App的接口。App内AI助手支持大模型在单个应用内为用户提供支持，增强现有App的语音交互和智能化能力。比如办公软件或社交软件内部的AI助手，每个助手通常针对其所在应用的特定功能和用例进行优化。

汽车行业大模型落地的应用包括智能座舱和自动驾驶等。智能座舱为用户提供更为贴心的交互体验。用户可以直接与座舱数字人对话，实现用车指导、导航、娱乐、服务信息查询、聊天陪伴等全面贴心的服务。目前自动驾驶汽车以“重感知 + 轻地图”的方案为主，因此需要车辆自主完成行驶任务并做出智能的决策，该方案已在多个城市进行测试。

#### 1.4.4 可信任性及可解释性

随着大模型应用的日益增多，社会对大模型的可信任性、数据与隐私安全、滥用风险等问题越发关注。确保模型的安全性和遵守伦理标准将成为研发工作的重要组成部分。模型的可信任性是指模型在执行任务时的可靠性、安全性和符合道德标准的程度。为了提高大模型的可信任性，技术人员需要采取多种策略，包括改进数据处理方法、增强模型检验和验证流程、引入透明度和解释性机制、实施严格的安全措施以及进行持续的伦理和社会影响评估。此外，随着技术的发展，也需要不断更新相关的法律法规和政策指导，以促进AI技术的健康发展和社会接受度。

同时，大模型决策过程和结果的可解释性也变得越来越重要。大模型的可解释性是指模型的决策过程、逻辑推理和结果输出对开发者、用户以及监管机构来说是可以理解和透明的。一个具有良好可解释性的模型应该能够清晰地展示其决策过程。这意味着对给定的输入，模型应能提供为什么会给出特定输出的解释。这有助于用户理解和信任模型的判断。对大模型而言，其内部的运作往往像一个黑盒子一样不可见。可解释性要求对这些复杂结构的内部机制进行一定程度的解读。当模型做出错误的预测时，可解释性可以帮助我们理解导致错误的原因。这对调整和改进模型至关重要，同时可以防止错误的决策对实际应用造成影响。研究人员正在探索各种方法和技术来提升模型的可解释性，包括可视化工具、注意力映射、局部解释模型、反事实解释等，以便用户能够理解和信任模型的输出。这些技术旨在揭示模型是如何工作的，以及它如何得出特定的结论。随着AI越来越多地融入关键决策过程中，可解释性成为构建信任和可靠性的关键要素。

#### 1.4.5 自我学习
大模型的自我学习能力是人工智能领域中一个重要的发展方向，它使得模型能够像人类一样通过经验学习和适应环境。自我学习具有以下特征。

1. **数据驱动学习**：大模型通过处理大量的数据，学习数据中的模式和规律。这种学习过程不限于初始训练阶段，而是持续进行，使得大模型能够随着时间的推移不断进步。

2. **算法自适应**：大模型通常采用复杂的机器学习算法，如深度学习，这些算法能够自动调整模型参数，以适应新的数据和任务。这种自适应能力是自我学习的关键。 

3. **反馈循环**：在自我学习的过程中，大模型不仅依赖于数据，还依赖于外部反馈。这种反馈可以是用户的输入、环境的变化信息或其他形式的信号，以帮助模型识别和纠正错误，从而提高性能。 

4. **知识积累**：随着模型处理的数据量增加，其知识库也在不断扩展。这种知识积累使得模型能够处理更复杂的问题，并在新的情境中做出更准确的预测。 

5. **自我迭代**：大模型的自我学习能力还表现在每次学习都会产生新的知识上，这些新知识又成为下一次学习的基础，形成正向的自我增强循环。 

6. **减少人工干预**：随着自我学习能力的提升，大模型对人工干预的需求减少。这不仅提高了效率，还减少了对专家知识和资源的依赖。 

7. **应用广泛**：自我学习能力使得大模型在各种应用场景中都表现出色，从自然语言处理、图像识别，到医疗诊断、自动驾驶等，都能看到其应用。 

8. **促进创新**：自我学习能力为AI的创新提供了新的可能性。随着模型变得更加智能和自适应，它们能够探索新的解决方案和应用领域，推动技术进步。


### 1.5 本章小结
本章从自然语言处理的定义引出大模型的概念，进一步介绍了大模型的重大突破——智能涌现。接着，介绍国外、国内主流大模型的应用现状，对大模型快速发展中存在的问题和挑战，以及大模型的发展趋势进行了重点讲解。 
