![image](https://github.com/user-attachments/assets/58fd08eb-bfc8-4840-8997-5a42b19afa7a)



用好少样本学习示例，可以让大模型轻松适用于各种任务。
### 5. 迭代优化

对大多数人来说，很难一次就编写出完美、合适的提示。因此，我们需要先编写出基本的提示，之后根据模型的输出，不断调整提示的内容，进行迭代优化，直至编写出最合适的提示。

接下来，通过示例介绍提示优化和迭代的思路。给出一个产品的资料说明，要求大模型基于这些资料生成一份产品描述，步骤如下。

1）首先编写一个初始的提示，这个提示中包含了我们的基本需求。

```python
prompt = f"""
你的任务是帮助营销团队基于技术说明书创建一个产品的营销描述。
根据~~~标记的技术说明书中提供的信息，编写一个产品描述。
技术说明: ~~~{fact_sheet_chair}~~~
"""
```
2）通过初始提示，给出具体的提示。
```python
# 给定一份椅子的资料页。描述说它属于中世纪风格系列，产自意大利，并介绍了材料、构造、尺寸、可选配件等参数。假设你想要使用这份说明书帮助营销团队撰写电商平台的营销描述稿。
fact_sheet_chair = """
概述
美丽的中世纪风格办公家具系列的一部分，包括文件柜、办公桌、书柜、会议桌等。
多种外壳颜色和底座涂层可选。
可选塑料前后靠背装饰（SWC - 100）或10种面料和6种皮革的全面装饰（SWC - 110）。
底座涂层选项为：不锈钢、哑光黑色、光泽白色或铬。
椅子可带或不带扶手。
适用于家庭或商业场所。
符合合同使用资格。
结构
五个轮子的塑料涂层铝底座。
气动椅子调节，方便升降。
尺寸
宽度53厘米 | 20.87英寸
深度51厘米 | 20.08英寸
高度80厘米 | 31.50英寸
座椅高度44厘米 | 17.32英寸
座椅深度41厘米 | 16.14英寸
选项
软地板或硬地板滚轮选项。
两种座椅泡沫密度可选：中等（1.8磅/立方英尺）或高（2.8磅/立方英尺）。
无扶手或8个位置PU扶手。
材料
外壳底座滑动件
改性尼龙PA6/PA66涂层的铸铝。
外壳厚度：10毫米。
座椅
HD36泡沫
原产国
意大利
"""
```
将这个提示输入到模型，得到大模型输出的产品描述示例，如图6 - 9所示。

![image](https://github.com/user-attachments/assets/ace8d272-2c41-48b7-b1bf-3988671c358a)


大模型很好地将产品的说明资料转变成了产品描述文案，但是这份产品描述太长了。当客服将这个产品描述发送给用户时，用户可能根本没有耐心看完这个冗长的文本。因此，进一步，需要在提示中限制产品描述的字数。

3）优化提示，给出产品描述字数限制。

```python
# 优化提示，要求生成描述不多于50字
prompt = f"""
你的任务是帮助营销团队基于技术说明书创建一个产品的零售网站描述。
根据~~~标记的技术说明书中提供的信息，编写一个产品描述。
使用最多50个字。
技术规格: ~~~{fact_sheet_chair}~~~
"""
```
输出优化后的提示，得到大模型输出的产品描述如图6 - 10所示。

![image](https://github.com/user-attachments/assets/ee30bf03-0157-4848-8b15-fc0aeb69b41d)


这次生成的产品描述比第一次生成的简短了很多，但是我们发现，即使提示中设置了使用最多50个字，生成的内容还是超出了限制。这是因为大模型计算和判断文本长度时依赖于分词器，而分词器的字符统计并不完全准确。目前有多种方法可尝试控制大模型生成输出的长度，例如指定语句数、词数、汉字数等。虽然大模型对长度约束的遵循并非100%精确，但通过迭代测试可以找到最佳的长度提示表达式，使生成文本基本符合长度要求。这需要开发者对语言模型的长度判断机制有一定理解，并愿意多次试验来确定最可靠的长度设置方法。

由于减少了产品描述的字数，因此大模型在生成的过程中会尽量使用简洁的语言，同时会舍弃部分信息。在技术说明书中有很多具体数字参数的说明，但消费者并不关注这些，更想从宏观层面了解该产品，因此需要大模型在生成产品描述时更加侧重对产品的概述，减少具体参数的说明。

4）优化提示，侧重对产品的概述。

```python
# 优化后的提示，说明面向对象，应具有什么性质且侧重于什么方面
prompt = f"""
你的任务是帮助客服团队基于技术说明书创建一个产品的描述。
根据~~~标记的技术说明书中提供的信息，编写一个产品描述。
该描述面向卖家，因此应侧重对产品的概述，减少具体参数的说明。
使用最多80个字。
技术规格: ~~~{fact_sheet_chair}~~~
"""
```
输出优化后的提示，得到侧重产品概述的产品描述如图6 - 11所示。

![image](https://github.com/user-attachments/assets/fa56b0dc-719b-41df-974e-5302ef8a6122)



5）修改大模型输出为表格形式。
```python
# 要求大模型抽取信息后将信息组织成表格，并指定表格的列名、表名和格式
prompt = f"""
你的任务是帮助客服团队基于技术说明书创建一个产品的描述。
根据~~~标记的技术说明书中提供的信息，编写一个产品描述。
该描述面向卖家，因此应侧重对产品的概述，减少具体参数的说明。
使用最多50个单词。
在描述中，包括一个提供产品尺寸的表格。表格应该有两列：第一列包括尺寸的名称；第二列只包括以英寸为单位的测量值。
给表格命名为“产品尺寸”。
将所有内容格式化为可用于网站的HTML格式，将描述放在<div>元素中。
技术规格: ~~~{fact_sheet_chair}~~~
"""
```
大模型给出的HTML格式的产品描述如图6 - 12所示。

![image](https://github.com/user-attachments/assets/eed1c032-5356-4845-ad8b-4c1e5f868d86)


将HTML格式的元素转成具体的表格显示。
```python
from IPython.display import display,HTML
display(HTML(response))
```
具体表格形式的输出结果如图6 - 13所示。

![image](https://github.com/user-attachments/assets/62b80f61-6517-4484-a973-d72fcd583714)


6）判断用户情绪。在智能客服问答场景中，判断用户的情绪是十分重要的，可以通过提示来判断用户输入文本中蕴含的情绪。
```python
review = """
我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。
我很快就收到了它。在运输过程中，我们的灯断了，但是公司很乐意寄送了一个新的。
几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！
在我看来，Lumina是一家非常关心顾客和产品的优秀公司！
"""
prompt = f"""
判断以下用三个反引号分隔的产品评论的情感，如果是积极的就回答:“感谢你对我们产品的支持！”，如果是消极的则回答:“非常抱歉给你带来不愉快的体验，有任何问题请联系客服解决！”
评论文本: ```{review}```
"""
```
智能客服问答根据文本中蕴含的情绪返回的响应结果如图6 - 14所示。

![image](https://github.com/user-attachments/assets/632a769d-fac8-47fe-a7f3-65bc72839665)


### 6.3.3 第三方工具调用

在ChatGLM3中，模型可以自行调用工具作为辅助来完成任务。在智能客服场景中，工具调用可以让大模型完成原本无法完成的任务，订单查询任务便是其中的代表。订单查询需要用户个性化的数据，这些数据并没有包含在大模型的训练过程中，因此大模型无法完成查询任务。这时，可以借助第三方工具得到订单数据并传给大模型，这样大模型就拥有了订单查询的能力。

在ChatGLM3调用工具的过程中，我们需要按照官方要求编写一份工具模板，并传给大模型。下面来看一个示例。定义一个名为get_order_detail的工具模板，并指明必须包含参数order_id。接着，通过历史对话的形式将工具模板传给大模型，告诉大模型在解决问题的时候可以利用这个工具模板。之后，我们尝试查询订单，大模型会选择合适的工具模板来解析用户的问题并返回需要调用的方法名以及包含的参数。大模型输出的内容表示需要调用get_order_detail()方法，且参数order_id的值为10002051。get_order_detail工具模板的代码如下。
```python
tools=[
    {
        "name": "get_order_detail",
        "description": "查询订单的详细信息。",
        "parameters": {
            "type": "object",
            "properties": {
                "order_id": {
                    "description": "需要查询的订单编号"
                }
            },
            "required": ["order_id"]
        }
    }
]
system_info = {"role": "system",
               "content": "Answer the following questions as best as you can. You have access to the following tools:"}
history=[system_info]
query="查询编号为10002051的订单"
# 第一次调用模型
response,history=model.chat(tokenizer,query,history=history)
response
```
大模型输出结果如下。
```python
{'name':'get_order_detail','parameters':{'order_id':10002051}}
```
到目前为止是第一次调用大模型，大模型返回了需要调用的方法以及传入的参数，但是我们并没有定义get_order_detail()这个方法，接下来我们需要实现它。实现示例如下，读者可根据实际的业务场景进行不同的实现。
```python
def get_order_detail(
    order_id:Annotated[str,'The order number to be queried', True]
) -> str:
    """
    Get the detail for 'order_id'
    """
    order_id=int(order_id)
    # 加载订单数据源
    order_data=pd.read_excel('订单数据.xlsx')
    # 获取存在的订单编号
    order_id_list=order_data['商品编号'].to_list()
    # 判断输入的订单编号是否存在
    if order_id in order_id_list:
        # 获取订单编号的索引
        idx=order_id_list.index(order_id)
        order_detail=eval(order_data.loc[idx].to_json(force_ascii=False))
        # 时间戳格式在to_json后会被破坏，需要重新设置时间
        order_detail['下单时间']=order_data.loc[idx]['下单时间'].strftime("%Y-%m-%d %H:%M:%S")
        # 获取订单状态，如果是已取消，则不需要提供支付单号和支付时间
        if order_detail['订单状态'] == '已取消':
            del order_detail['支付单号']
            del order_detail['支付时间']
        else:
            order_detail['支付时间']=order_data.loc[idx]['支付时间'].strftime("%Y-%m-%d %H:%M:%S")
        return str(order_detail)
    # 如果订单编号不存在，则不进行查询
    else:
        return '查询的订单不存在'
```


实现方法后，需要使用官方提供的方法注册工具，接着利用工具获取订单的详情信息传给大模型，让它最终完成任务。在以下所示的代码中，register_tool方法和dispatch_tool方法都是ChatGLM3官方提供的方法，register_tool用来注册自定义的工具，dispatch_tool用来调用工具，将得到的结果输入大模型完成查询任务。需要注意的是，根据官方规定，工具获得的值需要在role参数中指明，否则大模型会混淆。

```python
register_tool(get_order_detail)
res=dispatch_tool(response['name'],response['parameters'])
# 这里的role="observation"表示输入的是工具调用的返回值，而不是用户输入，不能省略
response,history=model.chat(tokenizer,res,role='observation',history=history)
response
```
智能客服调用第三方工具输出查询结果，如图6 - 15所示。


![image](https://github.com/user-attachments/assets/f7a9e7f0-4ff6-45e8-bff3-fac3c831ff52)


我们以历史对话的形式将第三方订单传给大模型，让大模型在解决问题的时候可以利用这个工具模板。实现订单查询，并输出查询结果。

### 6.4 应用部署

完成了基于大模型智能客服问答功能的开发之后，接下来，需要为应用构建一个可视化页面并部署至服务端。

我们使用Streamlit框架进行智能客服问答系统的框架部署。首先，需要安装Streamlit模块依赖，创建一个功能为智能客服部署框架的服务启动Python脚本文件。主要代码如下：

```python
# 获取用户输入
prompt_text = st.chat_input("请输入你的问题")
# 如果用户输入了内容，则生成回复
if prompt_text:
    input_placeholder.markdown(prompt_text)
    history = st.session_state.history
    show_history = st.session_state.show_history
    show_history.append(
        {'role': 'user', 'content': prompt_text}
    )
    # 识别用户想要查询的物体
    recognize_prompt = f"""
    请识别用三个反引号括起来的文本中用户想要查询什么。如果识别成功，只需要输出识别的商品；如果识别失败，则输出识别失败。
    ```{prompt_text}```
    """
    recognize_resp =chat_model.request(chat_model.getText('user',recognize_prompt))
    # 如果识别失败，则返回“无法识别你需要查询的商品”。
    if recognize_resp == "识别失败":
        response = "无法识别你需要查询的商品。"
    message_placeholder.markdown(response)
    history.append(
        {'role': 'user', 'content': recognize_prompt}
    )
    history.append(
        {"role": "assistant", "content": response}
    )
    show_history.append(
        {"role": "assistant", "content": response}
    )
else:
    # 若识别成功，则通过相似度计算找到目标商品
    item_embedding = model.encode(recognize_resp)
    sim_score = util.pytorch_cos_sim(embeddings, item_embedding)
    # 若识别出的商品不存在
    if sim_score.max() < 0.8:
        response=f"非常抱歉，我无法为你提供关于{recognize_resp}的信息。"
    else:
        target_item = item_list[sim_score.argmax()]
        target_item_des = '\n'.join(item_dict[target_item])
        # 将对话记录存储
        history.append(
            {"role": "system",
             "content": f"你是一位智能客服，你要热情且谦逊地回答用户的问题。下面用三个反引号括起来的是关于{target_item}的一些商品描述，你的回答要基于这些描述，不可捏造。~~~{target_item_des}~~~"}
        )
        history.append(
            {"role": "user", "content": prompt_text}
        )
        # 得到回复
        response = chat_model.request(question=history)
        history.append({"role": "assistant", "content": response})
        show_history.append({"role": "assistant", "content": response})
        message_placeholder.markdown(response)
    # 更新历史记录
    st.session_state.history = history
    st.session_state.show_history = show_history
```
在终端输入Streamlit run命令，即可启动智能客服问答系统服务，具体命令如下。
```python
streamlit run streamlit_demo.py
```
Streamlit会将上述的Python脚本文件部署到服务器，并设置相应的端口号，使用浏览器打开相应的URL链接即可查看，控制台日志输出信息如图6 - 16所示。


![image](https://github.com/user-attachments/assets/98f56721-e92c-449f-8ba6-c540c9ab253f)


使用浏览器打开相应的URL链接即可查看智能客服系统主界面，如图6 - 17所示。


![image](https://github.com/user-attachments/assets/5dbc9ecf-5d3a-43b8-a405-5fa992d1d8b9)


输入想要咨询的问题，再按下回车键，即可得到智能客服问答系统的答复，如图6 - 18所示。


![image](https://github.com/user-attachments/assets/ee8c651e-ddab-4db6-911f-c2fa7c247c93)


如果想对Streamlit框架了解更多，可参考Streamlit框架相关资料进行学习。

### 6.5 本章小结
本章从大模型在智能客服问答中的应用讲起，基于智谱AI开源的第三代基座大模型ChatGLM3模型，讲解如何搭建开发环境，以及利用ChatGLM3构建一个简单的多轮对话系统，实现多轮对话的智能问答。本章还讲解了提示设计在智能客服中的应用与第三方工具调用，以及应用部署。 
