
### 第7章 学科知识问答实践
智慧教育一直是最受关注的大模型技术落地应用场景之一。教育领域有大量的学科知识图谱构建及精准教学、个性化学习方面的强烈需求，为智慧教育带来了很大的想象空间。可基于大模型构建学科知识问答系统，进而提供精准教学及个性化学习服务。

#### 7.1 应用概述

基于大模型技术构建学科知识问答是AI和教育相结合的重要环节。学科知识大模型可以为用户提供快速、准确的学科知识获取途径，回答各种学科领域的问题，涵盖从基础概念到高级理论的广泛内容。用户可以通过与模型交互，直接获得所需的知识，而无须在大量资料中进行烦琐的搜索。

学科知识问答大模型可以成为学生、教师和技术人员的有益工具。学生可以通过向模型提问，深入了解和巩固学科知识。教师可以在教学过程中使用模型回答学生提出的问题，提供更多的解释和示例，帮助学生理解。另外，学科知识问答大模型可以为专业人士提供有力的支持。无论是医生、律师、工程师还是其他领域的专家，他们在日常工作中经常需要查找和理解大量的学科知识。学科知识问答大模型可以作为他们工作和学习的智能助手，快速提供相关信息和解答。最后，学科知识问答大模型可以为各种智能化服务和产品提供核心功能。例如，智能搜索引擎可以利用模型回答用户的问题，提供更准确和详细的搜索结果。


#### 7.2 环境构建
在项目实践之前，我们需要构建开发所需要的依赖环境及下载问答系统构建的框架。

##### 7.2.1 开发环境搭建
Langchain - Chatchat是基于Langchain与ChatGLM等语言模型构建的本地知识库问答系统。学科知识问答实践将基于Langchain - Chatchat的开源项目进行二次开发。在实践之前，我们需要获取问答系统构建框架的原始代码，并构建项目所使用的虚拟环境。首先，访问Langchain - Chatchat的GitHub页面，拉取项目仓库。


![image](https://github.com/user-attachments/assets/cadb3dfe-c681-4acc-966b-6322fa7f1cc4)


项目下载完成后，在Anaconda中创建一个新的虚拟环境，Python版本需要介于3.8～3.11之间。进入已下载的项目路径，输入pip install -r requirements.txt安装依赖文件。使用之前已下载的ChatGLM3。然后下载m3e - small嵌入模型，下载地址为：https://huggingface.co/moka - ai/m3e - small。在终端输入pip list，检查依赖是否全都正确安装，并完成基础模型的下载。

##### 7.2.2 项目参数配置

完成下载之后，需要进行项目参数配置。配置文件在config文件夹下，包括basic_config.py、kb_config.py、model_config.py、prompt_config.py、sever_config.py等。


![image](https://github.com/user-attachments/assets/8c018d7f-ea3a-458d-b5ca-66a2bed53749)


我们主要配置model_config中的参数，步骤如下。

1）找到embed_model中的m3e - small参数并设置本地模型路径。



```python
MODEL_PATH = {
    "embed_model": {
        "ernie-tiny": "nghuyong/ernie-3.0-nano-zh",
        "ernie-base": "nghuyong/ernie-3.0-base-zh",
        "text2vec-base": "shibing624/text2vec-base-chinese",
        "text2vec": "GanymedeNil/text2vec-large-chinese",
        "text2vec-paraphrase": "shibing624/text2vec-base-chinese-paraphrase",
        "text2vec-sentence": "shibing624/text2vec-base-chinese-sentence",
        "text2vec-multilingual": "shibing624/text2vec-base-multilingual",
        "text2vec-bge-large-chinese": "shibing624/text2vec-bge-large-chinese",
        "m3e-small": "",
        "m3e-base": "moka-ai/m3e-base",
        "m3e-large": "moka-ai/m3e-large",
        "bge-small-zh": "BAI/bge-small-zh",
        "bge-base-zh": "BAI/bge-base-zh",
        "bge-large-zh": "BAI/bge-large-zh",
        "bge-large-zh-noinstruct": "BAI/bge-large-zh-noinstruct",
        "bge-base-zh-v1.5": "BAI/bge-base-zh-v1.5",
        "bge-large-zh-v1.5": "BAI/bge-large-zh-v1.5",
        "bge-m3": "BAI/bge-m3",
        "piccolo-base-zh": "sensenova/piccolo-base-zh",
        "piccolo-large-zh": "sensenova/piccolo-large-zh",
        "nlp_gte_sentence-embedding_chinese-large": "damo/nlp_gte_sentence-embedding_chinese-large",
        "text-embedding-ada-002": "YOUR_OPENAI_API_KEY",
    }
}
```
2）设置API，配置密钥。

```python
# 具体注册及API key获取请前往https://xinghuo.xfyun.cn/
"xinghuo-api": {
    "APPID": "7061c4c6",
    "APISecret": "",
    "api_key": "",
    "version": "v2.0",  # 讯飞星火大模型可选版本包括v3.5、v3.0、v2.0、v1.5
    "provider": "XingHuoworker",
}
```
3）设置嵌入模型，这里设置的是第一步中embed_model字典中包含的模型名称。


```python
# 选用的嵌入模型名称
EMBEDDING_MODEL = "m3e-small"
```


4）设置默认使用的大模型。
```python
# 选用的LLM模型
LLM_MODELS = ["xinghuo-api"]
```


至
此，基本的配置已完成，分别执行以下命令进行大模型初始化。
```python
python copy_config_example.py
python init_database.py --recreate-vs
```

大模型初始化成功后，在config文件夹中会生成可用的配置文件。


![image](https://github.com/user-attachments/assets/5d0ce5d7-c4c9-4b4f-859f-1d04fe9cc07d)


知识库初始化完成后，会自动建立样本文件的向量库，在knowledge_base/sample文件夹下查看向量库缓存文件。


![image](https://github.com/user-attachments/assets/685a6aaa-d06c-492a-8484-744073859027)


至此，完成了开发环境搭建及项目参数配置。接下来介绍如何构建学科知识图谱。


#### 7.3 学科知识图谱
知识图谱作为推动AI发展的重要推动力量，具备高效的语义处理功能，可作为管理、分析现代知识并提供决策支持的工具。基于大模型技术构建学科知识图谱能够形成知识互补，用户可以通过与大模型交互，直接获得所需的知识。

##### 7.3.1 大模型与知识图谱

大模型在多项NLP任务上都展现了令人惊叹的表现，但是依旧存在部分不足。虽然大模型能够回答一些开放领域的通用问题，但是针对垂直领域内的问题回答得依然不好。且大模型以隐式的方法存储知识，在回答问题时还存在编造事实的问题，缺乏解释性。

知识图谱以三元组的形式显式地存储知识，天然具有可解释性。知识图谱以实体概念作为节点，以关系作为边，以直观、可视化的方式展示知识间的复杂关联关系，从而清晰呈现知识结构。同时，知识图谱可以提供额外的、结构化的以及高质量的知识，提高大模型在垂直领域中的问答表现。

大模型和知识图谱应用场景能力要求对比如下表所示。其中☆表示匹配程度，☆越多表示越匹配。

|场景|能力要求|大模型|知识图谱|
| ---- | ---- | ---- | ---- |
|智能对话|意图理解、上下文记忆、知识生成|☆☆☆☆|☆☆|
|内容生成加工|意图理解、内容分析、知识总结|☆☆☆☆|☆☆|
|知识创作|意图理解、内容分析、任务编排、多模型生成|☆☆☆☆|☆☆|
|机器翻译|意图理解、内容生成|☆☆☆☆|—|
|知识检索|要素提取、知识表征、相似度对比|☆☆☆☆|—|
|知识管理|结构化生成、知识存储、知识检索|☆|☆☆☆☆|
|辅助决策|专业知识、时效性数据、逻辑计算|☆|☆☆☆☆|


可以发现，大模型在内容生成方面表现良好，而知识图谱基本没有生成能力。但是在知识管理和辅助决策两方面，知识图谱展现了优秀的能力。因此，知识图谱结合大模型可以实现技术上的互补。

大模型能够动态调用第三方知识库，且可以通过网络参数存储知识，但决策过程难归因、解释、溯源。模型更新难度大，存在知识过时问题。大模型知识的通用性更强，适合高通用知识密度的应用场景，并且具有上下文感知能力、深层语义表示和少样本学习能力。但多模态内容采用模型参数存储，有语义对齐和不可解释性。

知识图谱使用静态知识库，可以通过三元组存储知识，结构清晰，查询简单，易于理解。显式地存储知识，有助于归因溯源，提高了模型行为的可解释性，便于更新、修改、迁移知识。知识图谱的知识领域性更强，适合高专业知识密度，低通用知识密度场景。知识图谱的图结构表达能力强，多模态知识按照知识表示形式存储。

知识图谱可以为大模型提供丰富的背景知识和上下文信息，从而提高模型的准确性。通过将知识图谱中的实体、关系和属性等信息整合到模型中，可以帮助模型更好地理解文本中的语义和语境，从而更准确地进行推理和预测。

知识图谱可以为大模型提供可解释性方面的支持。通过将知识图谱中的实体和关系与大模型的预测结果进行关联，可以更清晰地解释大模型的决策过程。这有助于提升用户对大模型的信任度，并促进大模型的实际应用。知识图谱中的实体和关系还可以作为先验知识被整合到模型中，减少模型的训练时间和数据需求。同时，知识图谱还可以提供快速的查询和推理能力，提高模型的响应速度和性能。

##### 7.3.2 学科知识图谱构建流程

学科知识图谱面向特定学科，应用于具体业务，对知识图谱的实用性及知识的准确度要求更高。学科知识图谱可以看成一个基于语义网络的学科知识库，需要依靠特定行业的数据来构建。在学科知识图谱中，实体属性与数据模式往往比较丰富，在图谱构建和应用过程中需要考虑不同业务场景下的学生、教师和技术人员等不同用户的需求。

学科知识图谱的构建流程主要包括数据获取、本体构建、知识抽取、知识融合和知识加工等几个步骤。

学科知识图谱可以从互联网中获取结构化、半结构化和非结构化的开放领域数据，也可以获得授权的电子化书籍资源，进一步获取教育领域的课题标准、教材、教案和试题集等。此外，大模型也包含很多学科相关的知识，可以通过指令让大模型自动生成学科相关的文本资源。

本体构建是知识图谱构建中重要的一环，构建方法主要包括自上而下的构建方法和自下而上的构建方法。其中，自上而下的构建方法可以在图谱构建的初期即可构建，一般是有明确的任务需求。通常由具备领域知识的专家来构建，用来指导知识抽取。当然，也可以将任务需求告诉大模型，让它完成本体构建。而自下而上的构建方法在知识抽取之后才能构建，一般对抽取出来的知识进行聚类以自动构建本体。


![image](https://github.com/user-attachments/assets/ac245183-0424-4578-a2ec-702015c93160)


知识抽取是指从半结构化、非结构化数据中，由具备领域知识的专家参与指导，通过标注教育领域数据，完成学科本体构建，进一步指导知识中的属性、关系、实体抽取。之后对结构化的数据进行整合。

知识融合指发现具有不同标识但是代表同一知识点的对象，合并为一个全局唯一的知识点。目前，知识融合通常采用的方法是聚类，其关键是定义相似性度量。相似性度量的定义包括：①字符相似，也就是两个知识点的描述信息是相似的；②属性相似，具有相同“属性 - 值”关系的实体可能是相似的；③结构相似，指具有相同的相邻知识点。不同学科知识体系也会存在某些描述同一类数据的情况，也需要将不同数据源的知识体系进行融合。在学科知识图谱中，学科知识本体模式匹配主要是寻找不同知识体系中的对应关系。知识融合包括概念融合、实体对齐和属性对齐。其中实体对齐包括实体消歧和指代消解。

知识加工是指对图谱中的知识进行质量评估，包含检查知识来源的可信度，检查知识是否错误或者陈旧等。将评估合格的知识并入知识图谱中，针对知识图谱的知识进行知识推理，并对知识推理的结果重新进行质量评估。

知识图谱的质量评估包括：构建前评估数据来源的可信度，构建中控制知识抽取、知识融合、知识加工的质量，构建后进行错误知识的发现与纠正、过期知识的更新、缺失知识的发现与补全。

##### 7.3.3 学科知识数据集
构建学科知识图谱，首先需要构建学科知识数据集，数据集主要包含以下3个文件。
1）nlp_triple.txt：包含NLP学科知识三元组，三元组的头尾实体是NLP学科的知识点，知识点关系简化为包含和先序两种关系。其中，包含是指一个大知识点拥有多个小知识点，先序是指在学习某个知识点前需要学习的其他知识点，学科知识三元组数据示例如图7 - 5所示。


![image](https://github.com/user-attachments/assets/6164c172-0458-4e7f-9f81-5720f09b4f5c)


2）knowledge_url.txt：包含知识点及其对应的介绍网页。



![image](https://github.com/user-attachments/assets/87fb1adf-a8c5-43d8-9555-b824b5e06dd7)


3）knowledge_ppt.txt：包含知识点及其对应的课件资源。


![image](https://github.com/user-attachments/assets/9221c5fd-25e4-411c-bafd-4c311864ef4f)


准备好了学科知识数据集，就可以开始进行解析并处理学科知识了。

##### 7.3.4 学科知识处理

基于准备的数据集，可以处理学科知识库并使用RAG完成学科知识问答。虽然我们准备了一些NLP学科知识图谱的数据，但大模型并不能直接理解这些数据。

首先处理knowledge_url.txt文件，该文件中包含知识点及其对应的介绍网址，我们需要处理并提示大模型二者之间的关系。
```python
# 处理knowledge_url.txt
with open("knowledge_url.txt",'r',encoding='utf-8') as f:
    ku_data=f.readlines()
    f.close()
ku_data=[data.rstrip().split(' ') for data in ku_data]
fwrite=open('./processed/knowledge_url.txt','w',encoding='utf-8')
for i in ku_data:
    fwrite.write(i[0]+'\n参考网页:'+i[1]+'\n\n')
fwrite.close()
```
处理后的knowledge_url.txt文档格式如图7 - 8所示。


![image](https://github.com/user-attachments/assets/dcde5fc0-6958-4e87-9b27-4e01f1ef2724)


接着处理knowledge_ppt.txt，该文件中包含的知识点及其对应的课件资源，但是在数据集中并不是所有的知识点都对应课件，因此我们对数据集做如下处理：
```python
# 处理knowledge_ppt.txt
with open("knowledge_ppt.txt", 'r', encoding='utf-8') as f:
    kp_data=f.readlines()
f.close()
kp_data=[data.rstrip().split(' ') for data in kp_data]
fwrite=open('./processed/knowledge_ppt.txt','w',encoding='utf-8')
for i in kp_data:
    if len(i) == 1:
        fwrite.write(i[0]+' 本知识点暂无本地资源可参考。\n\n')
    else:
        fwrite.write(i[0]+' 可参考本地资源: '+i[1]+'\n\n')
fwrite.close()
```
处理后的knowledge_ppt.txt文档格式如图7 - 9所示。


![image](https://github.com/user-attachments/assets/419be054-ec99-4f2c-88b4-fc935f1857bd)


最后处理nlp_triple.txt，大模型并不能很好地了解“包含”和“先序”这两种关系，且三元组会出现一对多的情况，需要进行整合。
```python
# 处理nlp_triple.txt
with open("nlp_triple.txt", 'r', encoding='utf-8') as f:
    nt_data=f.readlines()
f.close()
nt_data=[data.rstrip().split(' ') for data in nt_data]
knowledge_dict={}
for i in nt_data:
    try:
        key=(i[0],i[1])
        if key in knowledge_dict:
            knowledge_dict[key].append(i[2])
        else:
            knowledge_dict[key]=[i[2]]
    except:
        None
fwrite=open('./processed/nlp_triple.txt','w',encoding='utf-8')
for k in knowledge_dict:
    value=knowledge_dict[k]
    head,rel=k
    if rel == '包含':
        fwrite.write(head+' 推荐继续学习以下知识点: '+ ','.join(value)+'\n\n')
    else:
        fwrite.write(head+' 学习该知识点前需要具备以下知识: '+ ','.join(value)+'\n\n')
fwrite.close()
```
更改文档分割器，由于数据集中的数据格式并不是一段段文本，而是具有结构化的形式。因此，上面的处理过程以“\n\n”分割每个知识点。

处理后的nlp_triple.txt文档格式如图7 - 10所示。


![image](https://github.com/user-attachments/assets/389102ad-9c4b-44dd-ad15-1252798a1e4b)


在Langchain - Chatchat中，默认使用的分割器是ChineseRecursiveTextSplitter，该工具根据文本字数分割文档，但并不适用这里的数据集，我们在configs/kb_config.py中将分割器更改为CharacterTextSplitter，使用符号分割。
```python
# TEXT_SPLITTER名称
TEXT_SPLITTER_NAME = "CharacterTextSplitter"
```
根据学科知识数据集，处理学科知识，完成了学科知识图谱构建的准备工作，开始进行学科知识问答实践。

#### 7.4 应用开发
学科知识问答系统的应用开发包括对话功能设置、知识库构建以及基于Langchain - Chatchat的问答实践。

##### 7.4.1 功能设置
完成项目环境构建和配置步骤之后，在项目路径下输入startup命令启动项目。
```python
python startup.py -a
```
项目启动之后，终端会显示项目访问链接，我们可以通过浏览器打开链接查看项目。


![image](https://github.com/user-attachments/assets/9e0138d7-7b66-4665-b23b-519e1ce29a00)


页面左侧的导航栏可以查看拥有的功能，主要包括

对话和知识库管理两个功能：对话功能是和大模型对话，知识库管理功能是可以在页面编辑知识库。


![image](https://github.com/user-attachments/assets/662a1cc9-3cac-4566-87b3-d076a541cae9)


对话模式包含LLM对话、知识库问答、搜索引擎问答和自定义Agent问答。LLM对话是正常和大模型对话的模式，知识库问答在大模型回答时会检索知识库中有用的信息作为参考，搜索引擎问答在回答时会以搜索引擎在互联网中搜索的知识作为参考，自定义Agent问答会根据用户的查询调用工具来辅助完成问答。 
