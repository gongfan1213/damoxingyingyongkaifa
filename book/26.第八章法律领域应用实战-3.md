### 8.3.4 微调前后的对话问答对比（续）


![image](https://github.com/user-attachments/assets/6686ce5f-7fa1-4872-8548-f8f9fd9487e5)


基座模型输出的“交通肇事罪”的概念、特征和司法解释如图8 - 11所示。

指令微调后模型的输出如图8 - 12所示。

对基座模型和微调模型输出的内容进行分析，可以发现微调后模型的输出在很多地方和数据集的内容高度相似，证明了P - Tuning微调的有效性。不过，微调后模型输出的内容只能拟合一定长度的数据，这是因为微调的参数量并不多，无法拟合所有数据，因此输出的内容通常很短。本案例所展示的法律内容均来自互联网和模型输出，仅供学习使用，实际的法律问题请咨询专业律师。

### 8.4 部署验证

完成大模型的微调后，可以部署模型以供使用。接下来，我们将使用快速创建交互式界面的Python库Gradio和快速构建API的Web框架FastAPI来完成模型部署。在部署阶段，基于已经实现的模型推理功能代码，使用Gradio编写一个前端页面并将其注册到FastAPI中即可。

在指令微调阶段，需要对查询概念、特征和司法解释三种指令进行微调。

首先创建一个下拉框让用户选择具体查询的内容，接着构建一个文本框让用户输入想要查询的罪名，最后构建一个提交按钮，当单击该按钮时，将下拉框和文本框的内容传入相关方法，获得模型的回复并以Markdown格式返回到网页，示例代码如下。
```python
with gr.Blocks(title='法律罪名查询功能') as demo:
    drop_down=gr.Dropdown(choices=['查询概念','查询特征','查询司法解释'],label='请选择具体的功能')
    query=gr.Textbox(label='请输入查询的罪名：')
    btn=gr.Button(value='查询')
    btn.click(get_response,inputs=[drop_down,query],outputs=gr.Markdown())
```
单击按钮会调用get_response()方法，这个方法用来处理前端输入以及获得模型输出。该方法接收前端用户输入的function和query两个参数，并进行简单的空值判断：如果某个值为空，则提示相应的错误；如果不为空，则通过一定的规则将两者拼接起来获得具体查询结果。最后通过llm_generate()方法得到大模型输出并返回。实现代码如下所示。
```python
def get_response(function,query):
    if function=='':
        raise gr.Error('未选择正确的功能')
    elif query=='':
        raise gr.Error('未输入查询的罪名')
    else:
        query_dict={
            '查询概念':'查询以下罪名的概念：',
            '查询特征':'查询以下罪名的特征：',
            '查询司法解释':'查询以下罪名的司法解释：'
        }
        ins_query=query_dict[function]+query
        return llm_generate(model,tokenizer,ins_query)
```
至此，我们已经实现了一个简单的法律大模型问答系统。最后，我们将其注册到FastAPI中完成部署。首先创建一个FastAPI实例，接着使用mount_gradio_app方法传入创建的实例和Gradio页面即可。



```python
app=FastAPI()
@app.get('/')
def read_main():
    return {'message':'欢迎使用法律大模型问答系统'}
app=gr.mount_gradio_app(app,demo,path='/lawchat')
import uvicorn
# 填写部署服务器（host）的IP地址
# 根据实际部署服务器端口占用情况设置端口号
uvicorn.run(app,host='',port=8009)
```
部署后的法律大模型页面展示如图8 - 13所示。

![image](https://github.com/user-attachments/assets/a5aa7be0-178f-45d9-b5d3-8ed45a67dd12)


至此，我们完成了一个简单的法律大模型系统的实现及注册。

### 8.5 本章小结
本章从中文法律大模型实践讲起，首先基于开源大模型进行中文法律大模型对话微调，使用大模型微调框架DeepSpeed的参数配置，利用LoRA微调方法，通过只微调新增参数的方式，大大减少了特定领域任务的可训练参数数量。接着，以ChatGLM3 - Base作为基座模型，构建法律领域特定的指令微调数据集，采用P - Tuning进行指令微调，并进行指令微调效果评估。最后，基于微调模型构建中文法律知识问答系统，使用Gradio和FastAPI来完成模型部署。 
