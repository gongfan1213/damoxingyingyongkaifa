### 第9章 医疗领域应用实践

随着社会的发展和医疗技术的进步，大模型加快在垂直领域的落地，有望开创医疗领域应用新局面。基于开源大模型进行增量预训练、有监督微调以及进行直接偏好优化（Direct Preference Optimization，DPO），有助于构建精准的医疗领域大模型，从而为医疗专业人员提供宝贵建议并辅助做出合理决策。



#### 9.1 应用概述

大模型在多种医疗应用中显示出巨大的应用价值，如医疗知识问答、医患对话系统、病例内容生成等。此外，随着电子健康记录（EHR）、医学文献和病人生成数据的指数级增长，大模型经过训练后可以辅助做出科学的决策。

尽管大语言模型在医疗领域具有巨大的潜力，但仍存在一些重要且艰巨的挑战需要面对。当模型用于闲聊对话场景时，错误的影响较小。但在医疗领域使用时，错误的解释和答案可能干扰医生的医疗诊断和治疗计划，进而会对病人的治疗和护理结果产生影响，可能造成严重的后果。

医疗领域大模型提供信息的准确性和可靠性非常重要。例如，当有人问大模型关于孕妇可以用什么药的问题时，有些大模型可能错误地建议使用四环素。如果真按照这个错误的建议去给孕妇用药，可能会给孩子骨头生长带来不好的影响。鉴于医疗数据和应用的特殊性，如果想要在医疗领域用好大语言模型，需要根据医疗领域的特点对大模型进行设计和基准测试，避免大模型可能会带来的风险。


#### 9.2 医疗数据集构建

基于大模型构建医疗领域应用之前，需要构建医疗数据集，包括增量预训练数据集、有监督微调数据集、直接偏好优化数据集，以及模型评测数据集。

**9.2.1 增量预训练数据集**

在进行增量预训练（Continue Pretraining）之前，需要构建增量预训练数据集。我们选取《内科治疗指南》《内科疾病鉴定诊断学》《传染病学》等书籍的部分数据构建增量预训练数据集。数据集存放于项目目录下的data/pretrain文件夹下。数据格式为txt格式，数据示例。

![image](https://github.com/user-attachments/assets/3e547922-7d07-4699-a8d6-0fdab24cd0ae)


本数据集只供学习使用，在实际业务中进行模型增量预训练需要使用更大的模型和数据集，以获得更好的效果，数据无特殊格式要求，增量预训练是可选的步骤，读者可以跳过此步骤的数据构建，直接进行有监督微调数据集构建。通过实验测试可以发现，做领域知识注入，有监督微调比增量预训练效率更高。

**9.2.2 有监督微调数据集**

在进行有监督微调之前，需要构建有监督微调数据集，可在增量预训练模型基础上进行指令微调，以对齐指令意图，并引入医疗领域知识。我们使用Belle的抽样数据构建指令微调数据集。数据集存放于根目录下的data/finetune文件夹。

![image](https://github.com/user-attachments/assets/2873ba3f-4dd7-44b7-9273-d11793e61eaa)


其中，每条对话数据（Conversations）是由多个键值对构成的对话列表。列表的第一个键值对为人类用户的问题，键为人类用户，值为提出的具体问题。列表的第二个键值对为大模型给出的回答，键为大模型，值为给出的具体回答。为了能够迅速验证训练代码的可用性，我们仅使用了少量样本数据，实际业务需要使用更大的数据集，以获得更好的效果。

**9.2.3 直接偏好优化数据集**
在进行直接偏好优化（Direct Preference Optimization，DPO）之前，需要构建直接偏好优化数据集。我们从文件reward数据集抽取500条数据构建直接偏好优化数据集，数据集位于data/reward文件夹，数据示例。

![image](https://github.com/user-attachments/assets/e9deb7c1-4711-440b-b008-440dec7a0c82)


每条数据均为一个键值对构成的字典，键为标签，值为标签内容。每条数据都包括一系列系统提示（system）、历史对话（history）、用户提问（question）以及响应标签。其中，response_chosen为标注员选中的答案；response_rejected为标注员拒绝的答案。这些答案参考了本草模型SCIR-HI/Huatuo-Llama-Med-Chinese给出的答复。这是仅作偏好优化过程的展示，不代表专业医生的建议。

**9.2.4 模型评测数据集**

为了进行大模型评测，我们选用医疗数据集CMB（A Comprehensive Medical Banchmark in Chinese（2023））作为大模型评测数据集，该数据集分为CMB-Exam和CMB-Clin两部分，其中，CMB-Exam为全面、多层次评估医学知识的医学考试题目数据集，CMB-Clin为临床项目数据集。二者的数据说明。

CMB-Exam数据集包括Structure（6个主要类别和28个子类别）、CMB-test（每个子类别有400个问题，总共11 200个问题）、CMB-val（280个问题，附有解决方案和解释，用作思维链和少样本学习的数据源）和CMB-train（269 359道医学知识习题） 。

CMB-Clin包括74例复杂医学问诊。

![image](https://github.com/user-attachments/assets/55aac36c-67b4-4f9e-83f2-6864ea18689c)

![image](https://github.com/user-attachments/assets/696d40d5-17d4-4593-b333-4616c31ddc4d)

![image](https://github.com/user-attachments/assets/2b1d63a9-1893-4b33-b7f9-49c5b9a1b60b)

![image](https://github.com/user-attachments/assets/0d5b65c4-7892-4b3d-b574-5a618d36673a)

![image](https://github.com/user-attachments/assets/31800d60-4167-496f-bdfa-4e0bc99af129)


#### 9.3 增量预训练与微调
构建完数据集之后，可以基于数据集进行增量预训练、有监督微调，以及直接偏好优化。

**9.3.1 增量预训练**

完成了增量预训练数据集预处理，还需要编写增量预训练代码。接下来采用GLM的对话版本GLM-4-9B-Chat作为基座模型进行预训练。增量预训练代码文件为pretraining.py，训练Shell脚本为run_pt.sh，训练数据使用增量预训练数据集，增量预训练代码文件的执行逻辑如下。

1. **导入依赖包**：导入了如math、os、from dataclasses import dataclass, field等一系列在模型训练中需要用到的包和模块，这些依赖包为后续的模型训练、数据处理、参数设置等操作提供了基础功能支持。

2. **设置模型预训练相关的参数**：通过定义ModelArguments类来设置与模型、配置、分词器相关的参数，例如model_type（模型类型）、model_name_or_path（模型名称或路径）、tokenizer_name_or_path（分词器名称或路径）等，这些参数决定了使用何种模型进行预训练以及相关的初始化设置。

3. **定义各函数并加载训练集**：
    - **default_tolerance_data_collator函数**：用于处理训练数据，当输入的特征数据存在问题时进行特殊处理，确保数据能够正确用于训练，例如对标签数据进行类型转换和特殊处理，保证张量以正确的类型创建。
    - **tokenize_function函数**：对输入文本进行分词处理，设置截断、填充等参数，将输入文本转换为模型可处理的格式，并将input_ids复制到标签上进行语言建模，适用于掩码语言建模（如BERT）和因果语言建模（如GPT）。
    - **tokenize_wo_pad_function函数**：在不需要填充的情况下对文本进行分词处理。
    - **group_text_function函数**：将数据集中的所有文本连接起来，并按照指定的block_size大小进行分块，同时处理剩余的少量文本块，确保数据能够以合适的格式输入模型进行训练。
4. **加载模型和分词器**：通过上述定义的函数对训练数据进行处理后，加载模型和分词器，为后续的训练过程做准备。
5. **模型训练及评估**：根据设置的参数和加载的数据进行模型训练，包括是否使用PEFT（Parameter-Efficient Fine-Tuning）技术、设置训练相关的超参数（如学习率、训练轮次、梯度累积步数等）、对模型进行训练和评估，在训练过程中记录训练指标（如损失函数值、准确率等），并保存训练过程中的检查点，以便后续评估和调整模型。
6. **查看训练结果**：训练完成后，查看训练过程中记录的指标，如损失函数值、梯度值、学习率、训练轮次epoch等信息，同时保存训练过程中的相关数据（如训练指标、模型状态等），并根据需要将LoRA（Low-Rank Adaptation）模型权重合并到基础模型中，保存合并后的模型到指定目录。

编写训练用的Shell脚本。显存参数可以根据GPU的实际情况进行修改，当前参数采用的基础模型是GLM4，显卡为A40，已配置总显存为96GB。
训练过程控制台显示包括损失函数值loss、梯度值grad_norm、学习率learning_rate、训练轮次epoch等信息。
在训练过程中，还会保存模型的检查点，根据距离矩阵评估算法性能（Eval Metrics）。
模型默认使用LoRA训练模型，LoRA权重保存在adapter_model.bin文件，LoRA配置文件是adapter_config.json，合并到基础模型的方法参见merge_peft_adapter.py。
日志保存在glm4-pt-v1/runs目录下，可以使用Tensorboard查看，启动Tensorboard的方式如下：tensorboard --logdir glm4-pt-v1/runs --host 0.0.0.0 --port 8009 。
将LoRA模型权重合并到GLM-4-9B-Chat，将合并后的模型glm4-pt-merged保存到--output_dir指定的目录下，合并方法如下。
```bash
python merge_peft_adapter.py \
--model_type chatglm \
``` 
