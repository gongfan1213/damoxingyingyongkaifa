### 9.3.2 有监督微调

完成有监督微调数据集预处理后，需编写有监督微调代码，涉及文件和工作如下：

- **文件**：有监督微调代码文件为supervised_finetuning.py，训练Shell脚本为run_sft.sh。训练数据用已构建的有监督微调指令对话数据集，生成模型用增量预训练阶段的glm4-pt-merged 。其代码执行逻辑与增量预训练一致。

- **工作内容**：包括导入依赖包、设置参数、定义函数并加载训练集、加载模型和分词器、模型训练及评估、查看训练结果，具体可参见9.3.1节增量训练代码。

- **Shell脚本**：显存参数依GPU实际情况修改，当前基础模型是glm4-pt-merged，显卡A40，总显存96GB 。脚本内容如下：

```bash
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node 2 supervised_finetuning.py \
    --model_type chatglm \
    --model_name_or_path ./glm4-pt-merged \
    --train_file_dir ./data/finetune \
    --validation_file_dir ./data/finetune \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --do_train \
    --do_eval \
    --template_name glm4 \
    --use_peft True \
    --max_train_samples 1000 \
    --max_eval_samples 10 \
    --model_max_length 4096 \
    --num_train_epochs 1 \
    --learning_rate 2e-5 \
    --warmup_ratio 0.05 \
    --weight_decay 0.05 \
    --logging_strategy steps \
    --logging_steps 10 \
    --eval_steps 50 \
    --evaluation_strategy steps \
    --save_steps 500 \
    --save_strategy steps \
    --save_total_limit 13 \
    --gradient_accumulation_steps 1 \
    --preprocessing_num_workers 4 \
    --output_dir glm4-sft-v1 \
    --overwrite_output_dir \
    --ddp_timeout 30000 \
    --logging_first_step True \
    --target_modules all \
    --lora_rank 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --torch_dtype float16 \
    --fp16 \
    --device_map auto \
    --report_to tensorboard \
    --ddp_find_unused_parameters False \
    --gradient_checkpointing True \
    --cache_dir ./cache
```
训练中会衡量模型在训练数据上的性能，保存检查点，评估算法性能，控制台显示信息如图9-12。模型默认用LoRA训练，权重存于adapter_model.bin，配置文件是adapter_config.json ，合并方法参见merge_peft_adapter.py 。日志存于glm4-sft-v1/runs目录，可用Tensorboard查看，启动命令：tensorboard --logdir glm4-sft-v1/runs --host 0.0.0.0 --port 8011 ，网页显示信息如图9-14。

![image](https://github.com/user-attachments/assets/121a20b2-53a7-48ec-87fc-ef00d9b6ed1f)

![image](https://github.com/user-attachments/assets/b8b47a45-edb1-4c43-8d66-3213522fc626)

![image](https://github.com/user-attachments/assets/6137669f-ab8b-4ea2-86fd-b9231f38333b)


将LoRA模型权重合并到glm4-pt-merged，合并后模型为glm4-sft-merged，保存到--output_dir指定目录，合并方法：
```bash
python merge_peft_adapter.py \
    --model_type bloom \
    --base_model glm4-pt-merged \
    --lora_model glm4-sft-v1 \
    --output_dir ./glm4-sft-merged
```
合并过程控制台显示信息如图9-15。至此，完成有监督微训练。

![image](https://github.com/user-attachments/assets/1799030f-c7c9-426c-b555-8eab5c365fa7)

![image](https://github.com/user-attachments/assets/f3698ddf-e321-4ad6-8428-fe83b496d348)

![image](https://github.com/user-attachments/assets/756b9553-10ce-4daf-8bbd-007a8bb35a82)

![image](https://github.com/user-attachments/assets/99658830-4426-4af5-a271-7395a1f2d06d)


### 9.3.3 直接偏好优化
完成有监督微调后，需编写直接偏好优化（Direct Preference Optimization，DPO）处理代码 。通过直接优化语言模型控制其行为，无需复杂强化学习，可学习人类偏好，比RLHF更易实现、训练，效果更好。涉及文件和工作如下：
- **文件**：代码文件为dpo_training.py，训练Shell脚本为run_dpo.sh 。训练数据用直接偏好数据集，生成模型用有监督微调模型glm4-sft-merged 。代码执行逻辑与增量预训练一致。
- **工作内容**：包括导入依赖包、设置参数、定义函数并加载训练集、加载模型和分词器、模型训练及评估、查看训练结果，具体参见9.3.1节 。
- **Shell脚本**：显卡参数依GPU实际情况修改，当前基础模型是glm4-sft-merged，显卡A40，总显存96GB 。训练过程控制台显示包括损失函数值loss、梯度值grad_norm、学习率learning_rate等信息，如图9-16 。训练中会衡量模型性能，保存检查点，评估算法性能，控制台显示具体信息如图9-17 。

![image](https://github.com/user-attachments/assets/1ccbac80-4d2f-492f-8312-caa3898bb83f)

![image](https://github.com/user-attachments/assets/a0386d4f-f2e4-435f-bb63-fde405245009)

![image](https://github.com/user-attachments/assets/6e8b72f9-d8ba-4de7-907a-ecaf1936f847)

![image](https://github.com/user-attachments/assets/4538b0f9-6a7d-4c53-bce1-f91075b00b34)

![image](https://github.com/user-attachments/assets/1b42ed2e-eb89-418f-a0e1-f5f528afb077)


模型默认用LoRA训练，权重存于adapter_model.bin，配置文件是adapter_config.json ，合并方法参见merge_peft_adapter.py 。日志存于glm4-dpo-v1/runs目录，可用Tensorboard查看，启动命令：tensorboard --logdir glm4-dpo-v1/runs --host 0.0.0.0 --port 8012 ，网页显示信息如图9-19 。

![image](https://github.com/user-attachments/assets/dbcd2cd0-9c1b-46b5-8748-95a154c79857)


将LoRA模型权重合并到glm4-sft-merged，合并后模型为glm4-dpo-merged，保存到--output_dir指定目录，合并方法：
```bash
python merge_peft_adapter.py \
    --model_type chatglm \
    --base_model glm4-sft-merged \
    --lora_model glm4-dpo-v1 \
    --output_dir ./glm4-dpo-merged
```
合并过程控制台显示信息如图9-20。至此，完成直接偏好优化过程。

### 9.4 部署验证
完成大模型的增量预训练、有监督微调以及直接偏好优化后，可部署模型并验证生成文本效果 。推理脚本示例命令：
```bash
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --model_type chatglm \
    --base_model glm4-dpo-merged \
    --tokenizer_path glm4-dpo-merged \
    --interactive
```
**参数说明**：

- **--model_type {base_model_type}**：预训练模型类型，如LLaMA、BLOOM、ChatGLM等。
- **--base_model {base_model}**：存放LLaMA模型权重和配置文件的目录。
- **--tokenizer_path {tokenizer_path}**：存放对应分词器的目录，不提供则默认与--base_model相同。
- **--template_name**：模板名称，如vicuna、alpaca等，不提供默认是vicuna。
- **--interactive**：以交互方式启动多轮问答，按行读取file_name中的内容进行预测。
- **--data_file {file_name}**：非交互方式下，将预测结果以JSON格式写入file_name。
- **--only_cpu**：仅使用CPU进行推理。
- **--gpus {gpu_ids}**：指定使用的GPU设备编号，默认0，多张GPU用逗号分隔，如0,1,2 。

推理过程控制台输出显示信息如图9-21 。以医疗领域问题“小孩发烧怎么办”为例，优化后的医疗大模型回复如图9-22 。至此，完成医疗大模型部署及问题回答效果验证，证明模型优化有效性。

![image](https://github.com/user-attachments/assets/c228cca0-b268-4834-862d-e3aafb114243)


![image](https://github.com/user-attachments/assets/fc49be41-a43a-475c-bd24-c4a76f1dbd3a)


### 9.5 模型评估
完成医疗大模型部署及验证后，基于已准备的模型评测数据集和评测工具OpenCompass进行评估。
#### 9.5.1 配置评估任务

在OpenCompass中，评估任务由待评估模型和数据集组成，可通过命令行或配置文件选择 。将医疗数据集CMB复制到项目根目录下的configs/datasets/cmb/data目录 。

医疗大模型微调采用GLM对话版本GLM-4-9B-Chat作为基座模型 。在Hugging Face类型的对话模型配置文件中编写实验完整配置，通过评估入口run.py直接运行 。配置文件是Python格式，需包含datasets和models两个字段 。

测试配置放于configs/eval_chat_demo.py，通过继承机制引入数据集（datasets）和模型配置（models） ，示例代码：
```python
from mmengine.config import read_base
with read_base():
    from .datasets.cmb.cmb_gen_dfb5c4 import cmb_datasets
    from .models.chatglm.hf_chatglm3_6b import models as glm_dpo_merged

datasets = cmb_datasets
models = glm_dpo_merged
```
OpenCompass预定义模型配置在configs/models下，在configs/models/chatglm/hf_glm4_9b_chat.py中进行配置，部分核心代码：

```python
from opencompass.models import HuggingFacewithChatTemplate
models = [
    dict(
        type=HuggingFacewithChatTemplate,
        abbr='glm4-dpo-hf-chat',
        path='../../../MedicalGPT/glm4-dpo-merged',
        max_out_len=1024,
        batch_size=8,
        run_cfg=dict(num_gpus=1),
        stop_words=['<endoftext>', '<user>', '<observation>']
    )
]
```

![image](https://github.com/user-attachments/assets/93649643-fe05-4c8d-bb7c-90dbfaf6feb6)



数据集配置文件目录为configs/datasets，可在命令行用--datasets，或导入配置文件（如configs/datasets/cmb/cmb_gen_dfb5c4.py ）配置，核心代码：

```python
cmb_datasets.append(
    dict(
        abbr='cmb' if split == 'val' else 'cmb_test',
        type=CMBDataset,
        path='./data/CMB/',
        reader_cfg=cmb_reader_cfg,
        infer_cfg=cmb_infer_cfg,
        eval_cfg=cmb_eval_cfg
    )
)
```
数据集配置评估方法常有ppl（辨别性评估）和gen（生成性评估），对话模型仅用gen评估 。configs/datasets/collections收录数据集集合方便综合评估，OpenCompass常用chat_OC15.py全面测试模型 。

#### 9.5.2 启动评估任务 
OpenCompass默认并行启动评估，首次运行可用--debug模式，按顺序执行并实时打印输出，启动命令：
```bash
python run.py configs/eval_chat_demo.py -w outputs/glm4_chat_demo --debug
```
正常情况下，屏幕显示启动进度条如图9-23。 


![image](https://github.com/user-attachments/assets/3a23f3b8-9afb-4f5b-9174-722fb459c252)


然后，可以按Ctrl+C组合键中断程序，并以正常模式运行以下命令。
```bash
python run.py configs/eval_chat_demo.py -w outputs/glm4_chat_demo
```
在正常模式下，评估任务将在后台以并行的方式执行，其输出将被重定向到输出目录outputs/demo/{TIMESTAMP}。前端的进度条只指示已完成任务的数量，而不考虑它们的成功或失败。任何后端任务失败都只会在终端触发警告消息。

以下是与评估相关的一些参数，可以帮助你根据环境配置更有效地完成推理任务。

1. **-w outputs/demo**：保存评估日志和结果的工作目录。在这种情况下，实验结果将保存到outputs/demo/{TIMESTAMP}。

2. **-r {TIMESTAMP/latest}**：重用现有的推理结果，并跳过已完成的任务。如果后面跟随时间戳，将重用工作空间路径下该时间戳的结果；若指定latest参数或未指定，将重用指定工作空间路径下的最新结果。

3. **--mode all**：指定任务的特定阶段。
    - **all**：（默认）执行完整评估，包括推理和评估。
    - **infer**：在每个数据集上执行推理。 
    - **eval**：根据推理结果进行评估。
    - **viz**：仅显示评估结果。 
4. **--max-num-workers 8**：并行任务的最大数量。在如Slurm之类的分布式环境中，此参数指定提交任务的最大数量。在本地环境中，它指定同时执行任务的最大数量。请注意，实际的并行任务数量取决于可用的GPU资源，可能不等于这个数字。

如果你不是在本地机器上执行评估，而是使用Slurm集群，可以指定以下参数。
- **--slurm**：在集群上使用Slurm提交任务。
- **--partition(-p) my_part**：Slurm集群的分区。 
- **--retry 2**：失败任务的重试次数。

### 9.5.3 可视化评估结果
完成医疗大模型的评估后，可以打印评估结果表格，包括dataset、version、metric、mode、glm4-dpo-merged。具体信息如图9-24所示。

![image](https://github.com/user-attachments/assets/421183e4-120f-430a-adc6-56b64f5b3007)


| dataset | version | metric | mode | glm4-dpo-merged |
| ---- | ---- | ---- | ---- | ---- |
| cmb | 1f8de9 | accuracy | gen | 82.41 |
| cmb_test | 385424 | accuracy | gen | 78.56 |

运行输出将定向到outputs/glm4_chat_demo目录，结构如下。
```
outputs/default/
    ├── 20240712_214002  # 每个实验一个文件夹
    ├── 20240712_215744  # 用于记录已转储的配置文件。如果在同一个实验文件夹中重新运行了不同的实验，可能会保留多个配置
    │   ├── configs  # 推理和评估阶段的日志文件
    │   ├── logs
    │   │   ├── eval
    │   │   └── infer  # 每个任务的推理结果
    │   ├── predictions  # 每个任务的评估结果
    │   ├── results  # 单个实验的汇总评估结果
    │   └── summary
    └── ...
```

通过上述步骤的操作，完成了基于开源大模型进行医疗大模型的增量训练与微调、大模型部署与推理，以及大模型效果评测的完整流程。更多有关模型预训练与微调的实践，感兴趣的读者可以阅读相关资源学习。

### 9.6 本章小结
本章从医疗大模型应用实践讲起，基于开源大模型进行医疗大模型增量预训练、有监督微调、直接偏好优化，构建精准的医疗大模型。最后，对医疗大模型进行部署与推理设置，并通过OpenCompass工具对大模型效果进行评测。 

