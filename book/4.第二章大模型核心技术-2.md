### 第2章 大模型核心技术
#### 及模型本身改动的方法，如提示工程或检索增强生成（Retrieval-Augmented Generation，RAG），模型微调固然消耗更多的时间和计算资源。然而，相较于从零开始预训练一个新模型，微调依然是一个效率更高、成本较低的选择，因为它只需对现有模型进行局部调整，且所需的训练数据也相对较少。

高质量数据集是决定模型微调后性能的关键因素。这些数据集需要与业务场景密切相关，并且数据标注需要高度精准。高质量数据集可以来自企业内部数据的提取或外部数据的采集，但都需要经过专门的数据标注处理。这些数据应具有代表性、多样性和准确性，并符合数据隐私等相关法规要求，只有使用足够的高质量数据进行训练，模型微调才能真正发挥作用。此外，模型微调策略也直接影响着大模型的最终性能。模型微调技术将在2.3节中重点介绍。

如果说预训练语言模型是一座金矿，那么有监督微调无疑是挖金矿的工具。为了提升模型的输出质量，我们需要设计高质量的有监督提示来对预训练语言模型进行微调。大模型有监督微调工作原理如图2-4所示。这些提示是以自然语言形式描述的指令，用于激发大模型的输出，涵盖文本生成、头脑风暴、开放问答、摘要、改写、闲聊、分类等多种类别。高质量的提示数据应当清晰、具体、聚焦、简洁。

![image](https://github.com/user-attachments/assets/3b7eef86-bffa-4fdd-aeaf-385061ace518)


**图2-4 有监督微调工作原理**

海量数据通过预训练大模型，生成高质量提示数据，涵盖文本生成、头脑风暴、开放问答、摘要、改写、闲聊、分类等，最终形成有监督微调大模型。


有监督微调要求精确的数据准备工作，这涉及将信息组织成结构化的问答对，即每个问题都与一个标准答案配对，以建立训练数据集。由于训练数据集被限定为这种严格的问答对格式，模型参数将逐步调整以捕捉和模拟这些数据的特定特征。高质量的问答对能显著提高模型的输出效果，通过定制的问答对，甚至能够引导模型专注于特定的专业领域，从而实现更加精确的训练成果。

通过采用P-Tuning、LoRA等微调技术，在预训练模型的基础上融入精心挑选的问答对数据，可以巧妙地调整模型参数。这一过程旨在增强模型对特定领域知识的理解，同时确保其通用语言处理能力不受损害。微调策略的目标是以最小的资源消耗，最大化地吸收微调阶段数据的特有规律。然而，如果微调不当，可能会削弱模型的泛化能力，导致其在非训练领域表现不佳。因此，用于有监督微调的数据通常来源于开源资源或网络上的高质量问答集合，并且需要通过专业数据处理，如进行人工筛选和校正，以确保领域的针对性。

数据集的规模至少应包含数十万条问答实例，虽然数量并非关键所在，但质量必须精良。在中文领域，数据集的容量通常可达上百GB，能够充分满足微调的需求。



#### 2.1.3 对齐优化

经过有监督微调的大模型能够根据特定的提示生成更加准确和相关的回复，从而增强大模型对特定领域任务的理解。为了进一步优化大模型性能，我们采用人类反馈的提示 - 问答对进行有监督微调，使输出更符合人类的偏好，从而产生用户更加满意的答案。

为确保大模型的输出与用户意图一致，我们使用奖励模型按照有用性、准确性和无害性对人类反馈的回复①②③④⑤进行打分排序。利用这些排序后的数据进行训练，优化奖励模型的评分机制，并运用强化学习的方法不断迭代训练大模型，如图2-5所示。这种训练方式帮助大模型更好地匹配人类的主观体验，同时持续吸收新数据，实现性能的持续提升和优化。

![image](https://github.com/user-attachments/assets/b9c38a04-c73c-4540-885f-b38875e61beb)


**图2-5 基于奖励模型打分的强化学习迭代训练大模型**

提示输入有监督微调大模型产生回复，奖励模型对回复打分，优化模型根据打分最大化奖励得分，从回复①②③④⑤依据有用性、准确性、无害性进行排序（3>4>2>1=5 ）。

RLHF的工作原理如下：

首先，针对提出的每个问题，模型生成多种可能的答案，并依据回答的质量对这些答案进行排序。基于一套详尽的标注规则，无论通过专业标注平台还是人工操作，标注员都能对大模型基于提示生成或补全（Completion）的内容进行精准的质量评分。

其次，奖励模型负责对模型的每个预测结果进行量化评分，这一过程需要反复训练，旨在使奖励模型的评分标准尽可能贴近人类标注员的实际判断。通过强化学习处理，奖励模型对答案的评分结果被用来指导有监督微调阶段的训练，其作用在于强化那些在奖励模型阶段获得了较高评分的回答，在后续的有监督微调训练中提升其预测概率，确保模型学习到人类偏好的输出模式。

最终，通过整合人类标注员的反馈，我们能够精调模型的输出，有效减少不确定性（即降低熵），从而提升结果对于人类而言的逻辑连贯性和可理解性。从模型效能的角度看，采用RLHF的方法显著超越了单纯的有监督微调策略，这表明在模型训练过程中融入人类评价的环节，确实能产出更为优质、更贴合人类认知习惯的生成结果。

简而言之，RLHF方法由于引入了人类偏好作为指导，能够引导模型生成更加合理且高质量的回答，相较于仅依赖模型自主学习的有监督微调，展现出了更佳的性能和更符合人类期待的表现。




### 2.2 Transformer模型

本节将深入探讨大模型技术的核心模型架构——Transformer。其中，2.2.2节～2.2.8节详细介绍了Transformer模型涉及的基础组成与训练技术细节，已掌握该基础知识的读者，可以直接跳至2.2.9节。


#### 2.2.1 Transformer模型概述
2017年，Google团队在其论文“Attention is All You Need”中首次提出了一种针对Seq-to-Seq（序列到序列）问题的Transformer模型架构。该架构旨在通过给定一个输入序列，经过Transformer模型的处理，最终生成一个相应的输出序列。

在Transformer模型结构中引入了编码器 - 解码器（Encoder-Decoder），并融合了注意力模块，这标志着一次重大的创新。相较于传统的RNN（循环神经网络）结构的编码器 - 解码器，Transformer模型采用了堆栈型结构，这一变革使得注意力机制在整个Transformer的运行过程中占据了核心地位。这种机制为精确建模不同词语之间的关系提供了强有力的支持，从而显著提升了模型的性能和效率。

Transformer模型基于编码器 - 解码器模型架构。编码器接收给定的输入序列，解码器输出最终的目标序列。Transformer模型架构如图2-6所示。

![image](https://github.com/user-attachments/assets/359f1988-f440-470f-a224-2976e561f051)


**图2-6 Transformer模型架构**

左侧编码器由N个Transformer块堆叠，包含位置编码、多头自注意力层、残差连接&规范化层、前馈神经网络层等；右侧解码器由N个Transformer块堆叠，包含位置编码、掩码多头自注意力层、多头自注意力层（从编码器到解码器）、残差连接&规范化层、前馈神经网络层等，最终经线性层、规范化指数函数输出概率。



编码器通常由多个多头自注意力层和前馈神经网络 （Feed-forward Neural Network，FNN）层组成的编码器层（Transformer块）堆叠而成。通过堆叠多层来提取和整合更丰富的上下文信息。多个编码器层的结构相同，但相互不共享权重。每个层后都接有一个规范化层（即层归一化，也称归一化层）和一个残差连接，残差连接会与原始输入相加，再传递给下一个子层。

解码器也是由多个解码器层（Transformer块）堆叠而成。每个解码器层在掩码多头自注意力层和前馈神经网络层中间增加了一个多头自注意力层（从编码器到解码器）。每个层后都接有一个规范化层和一个残差连接。解码器输出部分包括线性层（Linear）和归一化指数函数层（Softmax函数 ）。

前馈神经网络层以多头自注意力层的输出作为输入，并通过一个非线性激活函数的全连接网络对输入执行更复杂的非线性变换，例如ReLU（Rectified Linear Unit，修正线性单元）或GeLU（Gaussian Error Linear Unit，高斯误差线性单元）。


**提示**：这里再对Transformer模型架构中的几个概念进行一些补充说明。

（1）**输入向量**

Transformer的输入向量通常由三个部分组成。
 - **词嵌入**：这是最直观的部分，每个词被映射到一个固定长度的向量，用于表示该词的语义信息。词嵌入捕捉了词汇的语义和语法特性。
 - **位置嵌入（Positional Embedding）**：由于Transformer摒弃了循环结构，它不再依赖于序列的内在顺序来理解词与词之间的关系。位置嵌入被加入以赋予模型对序列中每个词位置的感知，这对于理解词序和构建上下文关系至关重要。
 - **段落或句子嵌入（Segment or Sentence Embedding）**：在处理两个或多个句子的输入时，例如在机器翻译中，可能会为每个句子添加一个特定的嵌入向量，以便模型可以区分不同的句子或段落。
这些向量的组合形成了Transformer的输入向量，使得模型能够处理变长的序列输入，同时保留序列内的位置信息和可能的句子边界信息。

（2）**输出向量**

Transformer的输出向量是一个固定长度的向量，它代表了输入序列中每个词的多维表示。在解码器阶段，这些输出向量被用来预测下一个词的概率分布。输出向量的每个元素都蕴含了关于输入序列中相应位置词的丰富信息，这些信息涵盖了词在上下文中的语义、语法角色以及与其他词的关联。通过这种方式，Transformer能够捕捉到词与词之间复杂的关系，从而在生成序列时做出更加精准的预测。

（3）**掩码多头自注意力**

掩码多头自注意力（Masked Multi-head Self-attention）是一种在深度学习模型中，特别是在Transformer架构中使用的技术。在处理序列数据时，它通过使用掩码来忽略或屏蔽某些不需要关注的部分，同时利用多头自注意力机制并行处理不同子空间的信息，从而提高模型对序列数据中不同部分重要性的识别和理解能力。这种方法在处理如NLP中的长文本或不完整输入时特别有用，能够提高模型的准确性和效率。

（4）**残差连接与规范化层**

残差连接（Residual Connection）与规范化层的结合，为深度神经网络带来了显著的优势。残差连接通过允许信息在网络层之间直接传递，有效地缓解了梯度消失 问题，使得模型能够在保持较高学习速率的同时，维持良好的收敛性。规范化层则通过对每一层的输入进行标准化处理，确保了网络中每一层的输入分布稳定，从而加速了训练过程并提高了模型的泛化能力。这两种技术的结合，使得深度神经网络能够在复杂任务上达到更优的表现。

（5）**位置编码**

Transformer模型通过使用位置嵌入（Position Embedding）来注入绝对或相对位置信息，从而在建模序列时为每个单词添加位置信息。这种嵌入方式使得模型能够理解序列中单词的顺序，这对于捕捉序列数据的上下文关系至关重要。通过位置嵌入，Transformer能够有效地处理序列数据，即使它本身并不依赖于循环结构来保持序列的顺序。

（6）**输出概率**

输出概率是解码器基于当前已有输入和上下文信息，通过归一化指数函数（Softmax）转换得到的下一个单词的预测概率分布。



#### 2.2.2 编码器与解码器
本节将重点对大模型的编码器 - 解码器，以及与解码器密切相关的因果解码器和前缀解码器进行区分讲解，并对模型架构的选择和应用进行总结。

1. **编码器 - 解码器流程**

Transformer解码器的工作流程可以用机器翻译任务来描述。在机器翻译任务中，源语言句子被转换成源语言的Token序列，目标语言句子同样被转换成目标语言Token序列。解码器的任务就是生成这样一个目标语言的Token序列。

（1）**Transformer编码器的工作流程**

Transformer编码器的具体工作流程如下。

1）编码器首先将源语言句子输入序列（源语言）中的每个单词（通常为一系列词或子词单元）或标记转换为一组固定维度的向量，以供模型理解和处理。该过程通过查找每个Token在预训练的嵌入矩阵中的对应向量来实现，这也是自然语言模型训练的通用预处理过程。

2）为了区分不同位置的单词并处理序列的顺序关系，位置编码被嵌入到输入向量中。即输入向量通常会与位置编码相结合，从而注入序列中Token的位置信息，确保Transformer模型具有捕捉序列顺序的能力。 

3）通过自注意力机制，模型对源语言的输入向量中不同Token的位置之间的相关性进行建模，以获取每个Token的位置的上下文信息。在多头自注意力层中，用每个Token的表示来计算一个注意力分数。该分数是通过查询（Query）和键（Key）之间的点积计算得出的，随后应用Softmax函数进行归一化处理，并确保注意力分布的合理性，参见2.2.3节所述的注意力机制。 

4）通过对所有Token的值向量进行加权求和来获得新的Token，其中其他位置的Token的权重由相应的注意力分数确定。这一过程确保了每个新Token能够包含整个序列的信息。 
