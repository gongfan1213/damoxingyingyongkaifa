### 2.2.6 规范化
预训练语言模型在训练过程中的不稳定一直是大模型研究面临的一个挑战。为了解决这一问题，规范化策略被广泛应用于稳定神经网络的训练。在Transformer模型中，主要使用的规范化方法包括LayerNorm、RMSNorm和DeepNorm等。

（1）**LayerNorm**
在早期的深度学习模型中，BatchNorm（批量归一化）通常用于处理固定长度的批量数据。然而，当面对长度可变的序列数据和小批量数据时，BatchNorm的应用会遇到困难。具体来说，由于BatchNorm是在批量维度上进行归一化的，这要求输入数据的批量维度必须固定。然而，对于长度可变的序列数据，由于每个序列的长度可能不同，无法将它们组成一个固定大小的批次。此外，在处理小批量数据时，BatchNorm可能会受到较大方差的影响，从而导致规范化效果不稳定。
为了解决这个问题，引入了LayerNorm（逐层归一化）方法。LayerNorm的核心思想是对每一层神经网络的激活值进行规范化处理，而不是对整个批次的数据进行规范化处理。具体而言，LayerNorm会计算每一层激活值的均值和方差，并利用这些统计量来重新居中和重新缩放激活值。这样做的好处是，每个样本都可以独立地进行规范化处理，而不受批次大小或序列长度的限制。

（2）**RMSNorm**
为了提升LayerNorm的训练速度和性能，技术人员提出了一种RMSNorm（均方根层归一化）的方法。RMSNorm通过仅使用激活值之和的均方根来重新缩放激活值，从而避免了使用传统的均值和方差。在Transformer模型中，RMSNorm在训练速度和性能方面展现出了优势。具体来说，RMSNorm会对每个特征维度计算其所有激活值的平方和，然后取其均方根作为缩放系数。这样，RMSNorm能够根据激活值的整体大小来调整激活值的阈值大小，无须显式计算均值和方差。
RMSNorm相比传统的均值和方差归一化方法具有诸多优势。首先，RMSNorm无须计算均值和方差，其计算过程更加高效，从而能够加快前向传播和反向传播操作，提升整体训练速度。其次，在Transformer模型中，RMSNorm能够准确捕捉输入数据激活值的整体分布情况，从而提高模型的表达能力和学习能力。此外，由于RMSNorm的缩放系数是基于激活值之和的均方根计算得出的，与具体的参数值无关，因此RMSNorm能保持对参数进行缩放和平移不变，从而使模型更加稳定和可靠。

（3）**DeepNorm**
DeepNorm是微软提出的一种用于稳定深层Transformer训练过程的技术。它通过将DeepNorm作为残差连接的一部分，使得Transformer的层数可以显著增加，甚至达到1000层。这种扩展能力展示了模型的稳定性和优异性能，并已应用于GLM-130B等模型中。

### 2.2.7 激活函数
由于神经网络处理的许多问题是非线性的，因此引入激活函数的作用是在神经网络中增加非线性。为了获得良好的性能，需要在前馈神经网络中适当设置激活函数（即将前一层神经元的激活值乘以权重加上偏置，然后输入激活函数，产生后一层的输出）。在Transformer模型中，常见的激活函数包括ReLU和GeLU（Gaussian Error Linear Unit，高斯误差线性单元）等。
其中，ReLU能够实现单侧抑制（即将一部分神经元置为0），从而使模型更为稀疏。然而，ReLU在0附近并不平滑，这就会引入偏置偏移，进而影响梯度下降的效率。此外，在训练过程中，如果参数在一次不恰当的更新后，某个ReLU神经元的输出为0，那么该神经元的梯度将始终为0，这种现象称为“死亡神经元”问题。
相比之下，GeLU在负值区域有一个非零的梯度，从而避免了“死亡神经元”问题。此外，GeLU在0附近比ReLU更加平滑，因此在训练过程中更容易收敛。然而，GeLU的计算较为复杂，因此需要消耗更多的计算资源。
现有的大模型广泛使用GeLU激活函数。特别是在最新的大模型（如PaLM和LaMDA）中也使用了GeLU的变体，如SwiGLU和GeGLU，这些变体在实践中通常能够取得更好的性能。

### 2.2.8 优化器
在训练过程中，Transformer定义了模型的结构和如何从输入数据产生输出，而优化器（Optimizer）则负责基于模型输出与真实标签之间的差距来调整模型参数。当Transformer构建好其复杂的多层编码 - 解码结构后，会通过前向传播产生预测输出。随后，优化器根据这些预测值与真实标签之间的差异（即损失），反向传播误差并更新模型权重。这一过程通常需要大量的迭代步骤，直到大模型的性能达到预设标准或者收敛。在整个流程中，Transformer和优化器是紧密协作的关系，前者负责构建和生成预测输出，后者负责调整参数以改进模型的表现，共同推动模型向着更优解的方向前进。
优化器通常基于梯度下降或其变体来实现。在每次迭代过程中，优化器会将损失函数的梯度作为输入，并根据该梯度来调整模型参数的值。常见的优化器包括随机梯度下降（SGD）、动量优化（Momentum）、AdaGrad、RMSProp和Adam等。本节主要介绍Adam系列优化器，其他优化器读者可以自行了解。
Adam优化器和AdamW优化器被广泛用于训练基于一阶梯度优化的大模型（例如GPT3），其本质是基于对低阶矩进行自适应估计。
Adam优化器是一种结合了动量优化和自适应学习率的优化算法。它使用梯度的一阶矩估计（均值）和二阶矩估计（未中心化的方差）来自适应地调整学习率。优点在于它能够自适应地调整学习率，并且对不同参数具有不同的学习率。
AdamW是Adam优化器的一个变种，它引入了权重衰减（Weight Decay）的概念。权重衰减是一种正则化技术，通过在损失函数中添加参数的L2范数惩罚项来减小参数数量。在标准的Adam优化器中，权重衰减是在参数更新之前应用的，但这可能导致参数更新的偏差。AdamW是通过将权重衰减应用到参数更新之后来解决这个问题的。AdamW可以更好地控制参数的更新偏差，并且在一些情况下可以提高模型的泛化能力。同时，Adafactor优化器也被用于训练大模型（例如PaLM和T5），它是Adam优化器的一种变体，专门用于在训练过程中保存GPU内存，显著降低了对存储空间的需求。

### 2.2.9 基于Transformer的大模型架构选择
基于以上Transformer各个组件不同技术特性的选择，可以组合出不同的模型架构。主流大模型的模型架构选择如表2-1所示。

**表2-1 基于Transformer的大模型架构选择**
|模型|架构类别|大小|模型层数|规范化|位置编码|激活函数|优化器|
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|GPT3|因果解码器|175B|96|LayerNorm|Learned|GeLU|Adam|
|OPT|因果解码器|175B|96|LayerNorm|Learned|GeLU|Adam|
|PaLM|因果解码器|540B|118|LayerNorm|RoPE|SwiGLU|Adafactor|
|LaMDA|因果解码器|137B|64|LayerNorm|RoPE|GeGLU|AdamW|
|LLaMA|因果解码器|65B|80|RMSNorm|RoPE|SwiGLU|AdamW|
|LLaMA-2|因果解码器|70B|80|RMSNorm|RoPE|GeGLU|AdamW|
|GLM-130B|前缀解码器|130B|70|DeepNorm|ReLative|ReLU|Adam|
|T5|编码器 - 解码器|11B|24|RMSNorm|ReLative| - | - |

**注**：表2-1中的Learned和Relative分别表示可学习的位置编码和相对位置编码。
- **可学习的位置编码**：相比较传统固定的正余弦编码，可学习的位置编码是通过训练过程自动学习的，位置编码是模型的参数之一，可通过梯度下降等优化算法进行优化。
- **相对位置编码**：这是一种根据位置之间的相对关系来编码序列的方法，考虑了序列中不同位置之间的相对距离和关系，并使用可学习的参数来对这些关系进行建模。

此外，传统的Transformer架构在处理长输入时还会面临着计算复杂度的挑战，在大模型的预训练阶段会极大地影响训练和推理的效率。为了缓解这一问题，技术人员在此之上设计了诸多新的语言建模架构，包括参数化状态空间模型，以及引入了递归更新机制的类似Transformer的架构。这些新架构的主要优点体现在两个方面：首先，这些模型能够像RNN一样递归生成输出，在解码过程中仅依赖于单个先前的状态，从而消除了传统Transformer中需要回顾所有先前状态的需求。这种设计使得解码过程更加高效，减少了计算资源的消耗。其次，这些模型保留了Transformer的并行编码能力，并能够并行处理整个句子。通过采用并行扫描（Parallel Scan）、FFT和长文本切块（Chunkwise Recurrent）等技术，这些模型能够充分利用GPU的并行性，实现高度并行和高效的训练。这些技术的应用显著提升了模型的处理速度和效率，使得它们在处理长文本时更加得心应手。

### 2.3 模型微调
本节介绍的大模型的模型微调技术，是指通过创建一系列包含具体指令及其预期结果的样本，采用监督学习的方法对预训练的大模型中的关键参数进行针对性调整的高效参数微调技术。因为微调过程中使用指令集，这种高效参数微调技术也称指令微调。这种方法能够使模型更好地理解和执行特定任务，提高大模型在实际应用中的准确性和效率。通过精心设计的指令样本，模型能够学习到如何根据给定的指令生成预期的输出，从而在各种任务中展现出更优的性能。
举个例子，“指令：列出一些适合周末的娱乐活动；输出：远足、整天在公园游玩、户外野餐、夜晚观影”，这构成了一个典型的问题（指令） - 答案。此类指令可以涵盖广泛的文本生成任务，如撰写邮件、修改句子等。鉴于人类能提出多样的指令，我们的目标是使模型在多种由指令主导的任务中展现出强大的泛化能力。
使用指令集进行微调的好处主要体现在以下几个方面。
1）通过利用丰富的问题 - 答案配对数据对大模型进行微调，有助于弥合模型原本专注于预测下一个词的任务与理解并执行用户指令之间的鸿沟。这样一来，模型的输出会更贴近用户的预期，显著提升了输出质量。 
2）相较于未经微调的模型，经过指令微调的模型在输入/输出方面更加规范化，因此具备更高的可预测性和可控性。这种规范化使得模型的呈现更加一致，便于用户理解和操作。 
3）指令微调在计算资源上的需求相对较低，尤其利用特定领域的指令数据进行微调，模型能够快速适应该领域的要求，无须从头开始全面训练，节省了时间和计算成本。这种高效性使得指令微调成为一种经济实用的模型优化策略。

#### 2.3.1 指令微调数据集
微调的核心追求是以最小化的资源消耗，催生出语言能力更为卓越的大模型。即便在数据量有限的环境下，指令微调依然能有效促使模型迅速掌握任务。以LIMA数据集为例，虽然仅仅包含1000条精挑细选的指令，但它成功让拥有65B参数的LLaMA模型，在超过300个高难度任务上的表现超越了使用多达5200条指令微调的GPT - davinci003模型。这一事实强有力地证明了：对于大模型而言，少量而精巧设计的指令足以激发其潜在的语言驾驭力。事实上，模型微调的最关键之处在于微调的指令数据集，数据集的样本质量越高、覆盖面越广，对模型泛化能力的提升也就越大。
微调数据集的构造方式主要包括以下两种。一种是通过对标注好的自然语言数据集进行整合，运用模板将文本的标签进行转换，从而在数据集中提取问题（指令） - 答案（输出）对。这种方法依赖于现有的高质量标注数据，通过适当的转换和整合，生成适合微调的指令 - 答案对，确保数据集的质量和多样性。另一种是利用大模型快速地生成给定指令的所需输出。该方式使用的指令可以通过人工采集，也可以通过一个小型手写种子指令进行扩展。这种方法利用模型的生成能力，可以快速生成大量的指令 - 答案对，适用于需要大量数据的场景，同时能够通过种子指令的扩展，增加指令的多样性和覆盖范围。
根据微调数据集的3类目标，可以将数据集分为：泛化到未曾见过的任务、在单轮对话中遵循用户的指令、在多轮对话中像人类一样提供帮助，常用指令微调数据集如表2-2所示。

**表2-2 常用指令微调数据集**
|类别|数据集名称|实例个数|任务个数|语言类型|构建方式|是否开源|
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|泛化到未曾见过的任务|UnifiedQA|75万|46|英语|人工构建|是|
||OIG|4300万|30|英语|人机混合|是|
||UnifiedSKG|80万| - |英语|人工构建|是|
||Natural Instructions|19万|61|英语|人工构建|是|
||Super-Natural Instructions|500万|76|55种语言|人工构建|是|
||P3|1200万|62|英语|人工构建|是|
||xP3|8100万|53|46种语言|人工构建|是|
||Flan 2021|440万| - |英语|人工构建|是|
||COIG| - | - | - | - | - | - |
|在单轮对话中遵循用户的指令|InstructGPT|1.3万| - |多语言| - | - |
||Unnatural Instructions|24万| - |英语|人工构建|否|
||Self-Instruct|5.2万| - |英语|InstructGPT生成|否|
||InstructWild|10万| - | - |InstructGPT生成|是|
||Evol-Instruct|5.2万|429|英语|GPT-3模型生成|是|
||Alpaca|5.2万| - |英语|ChatGPT生成|是|
||LogiCoT| - |2|英语|InstructGPT生成|是|
||Dolly|1.5万| - |英语|GPT-4生成|是|
||GPT4-LLM|5.2万| - |英语|人工构建|是|
||LIMA|1000| - |中英文|GPT-4生成|是|
|在多轮对话中像人类一样提供帮助|Chatgpt| - | - |英语|人工构建|是|
||Vicuna|7万| - |多语言|人工构建|是|
||Guanaco|534万| - |英语|用户共享|否|
||OpenAssistant|16万| - |多语言|LLaMaT8模型生成|否|
||Baize|111万| - |多语言|人工构建|是|
||UltraChat|67万| - |英语|ChatGPT生成|是|

用于训练泛化到未曾见过任务能力的数据集通常包含了多样化的任务，每个任务都有专门的指令和数据样例。模型在这类数据集上训练后，能够泛化到未曾见过的新任务上。例如，Super-Natural Instructions数据集包含了500万个来自1616个不同NLP任务的指令样本，涵盖了文本分类、信息提取、文本重写、文本创作等多种任务，并且将这些来自不同任务的指令统一用任务定义、正例和反例来描述。这种数据集的设计有助于大模型学习到任务间的共性和差异，从而在面对新任务时能够展现出良好的泛化能力。如下所示为数据集中的一个样本。
- **任务定义**：如果话语中包含闲聊策略，则输出“是”，否则输出“否”。
- **正例**：输入——“太棒了，我很高兴我们都同意这件事情。”“我也是，我希望你的露营之旅过得很愉快。” 输出——“是”。
- **解释**：当参与者希望对方有一次愉快的旅行时，他们会进行闲聊。
- **反例**：输入——“我们开始讨论今天的议程吧？首先，讨论一下合作项目。”“好的，我认为这个项目有潜力很大。我们已经准备好了一份详细的计划书。” 输出——“否”。
- **解释**：这种谈话围绕工作议程，属于商务交谈的范畴。因此，输出——“否”。

针对在单轮对话中遵循用户的指令的数据集，通常由指令及其相应的反馈组成，旨在精进大模型一次性回应指令的技能。例如，Dolly数据集就覆盖了7种类型的问题，包括开放式询问（为何人们热衷于喜剧片？）、封闭式询问（地球是不是平的？）、从维基百科检索信息（谁是鲁迅？）、概括维基百科内容（概述大模型的功能）、创意构思、分类（辨别哪些动物种类现存或已灭绝：象龟，巨龟。）以及创意写作（创作一篇关于某人意外发现家中隐秘房间的微型小说）。

针对在多轮对话中像人类一样提供帮助的数据集，往往涵盖多回合的随意交谈，经过训练后，大模型便能参与多轮互动，以

更人性化的方式提供帮助。例如，Baize数据集在构建过程中采用了自我对话的策略，通过设定对话模板（示例对话如下：[Human]: Hello! [AI]: Hi! How may I assist you?），让ChatGPT交替扮演用户与AI角色，以此生成对话数据，确保交流围绕特定的主题展开，且AI角色主要负责回应而非提问。 

当对能够处理多模态任务的大模型进行指令微调时，除了要求更广泛多样的指令样本外，指令本身也需更为精确详尽。多模态指令微调数据集如表2-3所示。例如，MUL-TINSTRUCT多模态指令微调数据集内含62项独特的多模态任务，均采用统一的Seq-to-Seq格式。这些任务来源于21个公开可用的数据集，跨越10个主要类别，每项任务附带5条由专家编撰的指南。另外，PMC-VQA数据集专为大规模医疗视觉问答设计，包含了227 000对涉及149 000张影像的问答，覆盖多种病症或医疗概念，适用于开放性问题及选择题形式的任务。LAMM数据集则是一个全面的多模态指令微调集合，聚焦于二维图像和三维点云的理解，包含186 000对语言图像指令 - 响应与10 000对语言点云指令 - 响应，旨在增强大模型对复杂视觉数据的解析能力。 

**表2-3 多模态任务指令微调数据集**

|多模态指令微调数据集|微调方式|样本数量|任务数|
| ---- | ---- | ---- | ---- |
|MUL-TINSTRUCT|图像 - 文本|每个任务5000个至500万个样本|62|
|PMC-VQA|图像 - 文本|22.7万个样本|2|
|LAMM|语言点云 - 文本|18.6万个样本|9|
| - | - |1万个样本|3| 
