
### 第2章 大模型核心技术

自从Transformer问世以来，凭借着其独特的自注意力机制，在NLP领域掀起了一场革命。它不仅大幅提升了模型训练的效率和效果，更开启了通往更加智能、更加精准的AI服务的大门。也正是因为Transformer这一划时代的技术，才促成了大模型的问世。

本章详细介绍了大模型的核心技术，与第3章大模型的拓展技术（即应用技术）一起作为本书的技术理论部分。本章的篇幅较多，蕴含的专业技术知识十分丰富，为照顾无AI方向技术储备的普通读者，对诸多技术概念作了简要介绍。同时，读者可参考附录了解大模型演进（其中包含了模型对输入处理的细节）。



### 2.1 大模型构建流程

在介绍大模型构建之前，我们需要先简单了解一下神经网络。大模型通常指的是具有大量参数和复杂结构的深度学习模型，它们能够处理和理解复杂的数据和任务。神经网络是大模型的基础，其构建流程如下。

1. **数据输入**：神经网络通过输入层接收数据，这些数据可以是图像、文本、声音等。

2. **特征提取**：输入数据在网络中向前传播，经过隐藏层 进行处理。每一层的神经元通过权重和偏置与前一层的输出相连接，并应用激活函数（参见2.2.7节）进行非线性转换，以提取更高层次的特征。

    - 在神经网络中，隐藏层是指位于输入层和输出层之间的一层或多层，其主要作用是提取和组合输入数据的特征，形成更高层次的抽象表示。这些隐藏层通过非线性变换增强了网络的表达能力，使得网络能够学习和模拟复杂的函数映射关系，从而在诸如图像识别、语音识别等任务中实现更准确的预测和分类。隐藏层的数量和结构设计是影响神经网络性能的关键因素。

3. **反向传播**：在训练过程中，网络的输出与期望的输出（标签）之间的差异可通过损失函数计算出来。这个损失值通过反向传播算法 传递回网络，逐层调整权重和偏置 。

4. **权重更新**：利用梯度下降或其他优化算法，根据反向传播得到的梯度信息，更新网络中的权重和偏置，以减少损失值。

5. **迭代训练**：通过多次迭代训练，不断优化网络参数，直到网络能够准确预测新的输入数据。

6. **输出生成**：训练完成后，神经网络能够根据输入数据生成预测结果，如分类标签、回归值或生成的文本等。


大模型是神经网络的一种扩展。通过增加网络的深度（更多的隐藏层）和宽度（每层更多的神经元），大模型能够显著增强其表达能力和学习能力。这种扩展使得大模型能够处理更复杂的任务，如NLU、图像生成和复杂的决策制定。然而，这种扩展也带来了更高的计算需求和训练成本，需要大量的数据与计算资源来训练和优化模型。

大模型的核心机制在于能根据输入的文本序列预测并生成后续的文字，直至遇到终止标志。这一过程本质上是对给定提示的扩展与完善。借助有监督微调（Supervised Fine-Tuning，SFT）与RLHF 等先进策略，使得大模型能精进其文本生成能力，使它不仅能流畅地补全文档，更能针对具体问题，展现出合理的逻辑性和连贯性，显著提升交互体验与实用性。

大模型通过提示工程优化提示内容，干预模型输出结果，并基于其内容总结和生成能力生成拟人化的回复，从而使推理结果更易于被用户理解和评价。大模型的构建流程如图2-1所示。

注意，RLHF中的奖励模型是一种机制，通过人类提供的反馈来定义和指导AI系统的行为，使系统能够根据这些反馈学习如何做出符合人类价值观和期望的决策。这种模型在强化学习中尤为重要，因为它能帮助AI理解哪些行为是“好”的，哪些是“坏”的，从而优化其决策过程，确保AI的行为与人类的道德和伦理标准相一致。

整体而言，该构建流程使大模型能够吸收广泛的文本信息，可处理多种语言形式和覆盖多种应用场景，从而展现出高度智能化的NLU与NLG能力。在理想的情况下，优秀的有监督微调RLHF应该能够让模型看起来几乎无所不知。然而，由于模型的预测机制是基于统计学原理的，仅能从文本模式中学习，因此缺乏真正的理解和推理能力，这使得大模型在处理复杂逻辑和深度理解任务时表现不足，无法完全达到人类的理解能力。




![image](https://github.com/user-attachments/assets/e2bc29b3-58ab-4673-bd00-9f2df666f68d)


### 图2-1 大模型的构建流程

1. 根据输入问题请求大模型

2. 通过大模型给出问题回答

3. 检索知识库中相关或相近的内容

4. 使用P-Tuning、LoRA等技巧微调模型优化模型参数

5. 使用微调模型进行预测

6. 针对模型输出的几个问题答案进行标注排名

7. 在有监督微调训练中使用RLHF的奖励模型强化人类反馈，以提升获得高分回答的预测概率

8. 将检索到的知识作为补充信息与问题合并，生成提示，输入到预训练模型中

9. 基于大模型内容总结和生成能力，生成拟人化回复，使得推理结果易于被用户理解和评价



但通过有监督微调对预训练语言模型进行微调，并利用RLHF优化模型输出，这一过程不仅强化了人机协同，还提升了模型生成内容的可解释性和质量，确保输出结果更加贴近人类认知标准。

下面将介绍大模型构建中的三个主要技术：预训练语言模型、模型微调和对齐优化。

#### 2.1.1 预训练语言模型

预训练（Pre-training）是指在一个大型无标签的数据集上训练模型的过程，目的是让模型学习到一些通用的特征和模式。这个“预”字就是“预先”的意思，即在真正执行特定任务之前，先让模型在大量数据上进行训练，从而获得一些基础但广泛的知识。预训练模型是经过预训练的模型，预训练语言模型则是通过将海量文本转换成计算机可解析的数字序列（Tokenization），实现针对语言结构的深度学习。在这个过程中，数据的质量与数量同等重要。尤其在构建超大规模的语言模型时，随着数据集和模型参数的迅速增多，高效算力成为必需。因此，我们运用大型算力集群，采用分布式并行训练策略，并辅以参数共享和精妙的算力管理调度，以确保训练过程的顺利进行。

以Transformer架构（参见2.2节）为基础的底层语言模型（Base Model，也简称基础型或基座模型）通过训练并产生词嵌入（Word Embedding）矩阵来预测序列中下一个可能出现的Token（标记），从而实现了语言的连续性。这种模型允许通过特定的提示信息来引导预测结果，从而增强了模型应用的灵活性。

预训练数据来源于多种渠道，包括百科全书、GitHub代码库、各类出版物与学术论文，以及网络论坛等。这些数据覆盖了广泛的领域和语种。尽管数据质量参差不齐，但其规模达到了TB级别，产生的Token数量同样惊人，为千亿级参数的大规模模型训练提供了坚实的基础。

传统NLP任务通常基于较小的数据集，Token数量少于10B，即模型参数不超过10亿个。相比之下，类似ChatGPT这样的模型在数据清洗后，训练数据量达到570GB，Token数量高达300B，拥有1750亿个参数（大致相当于96个Block （模块），每个Block包含4个隐藏层，每层12288个节点 ）。而更为先进的GPT-4级模型，其训练数据的Token数量更是达到了惊人的5000B，语言模型参数超过1万亿个。

由此可见，构建参数量巨大的大模型对并行计算能力和数据处理技术提出了极高的要求，这也是现代AI研究与开发的关键挑战之一。

如果希望在大模型的预训练阶段就侧重适配某个行业领域，除了整理大量的通用预训练数据外，还需要重点构建该行业的数据集，补充到预训练数据集中。如果行业的数据集的大小比通用预训练数据量小很多，则模型并不能有效学习到该行业数据集的特征，因此，更多时候是在模型微调阶段再加入行业数据集进行有监督微调或对齐训练，即精调大模型在该行业场景的输出结果。

在大模型的预训练阶段，会选择无监督学习、自监督学习（Self-Supervised Learning，SSL）等方式进行预训练。以自监督学习为例，它需要从数据本身生成的标签来学习数据的内在结构和特征，无须用人工标注的数据。完成预训练后，还需对大模型进行评估，并根据评估结果不断优化数据处理细节和模型架构。最后，针对优化后的大模型进行部署验证。大模型预训练过程如图2-2所示。

![image](https://github.com/user-attachments/assets/474c33b2-a9dc-4f0d-a5e0-55074e52b6b4)


### 图2-2 大模型预训练过程

|步骤|说明|
| ---- | ---- |
|数据集准备|收集和整理用于训练的大量数据|
|模型设计|确定模型的架构和参数设置|
|预训练|使用无监督学习、自监督学习等方式在大规模数据集上训练模型|
|数据处理和模型结构优化|根据训练情况优化数据处理方式和模型架构|
|模型评估|对训练后的模型进行性能评估|
|部署验证|将优化后的模型进行部署并验证其效果|


在预训练行业大模型时需要收集并标注大量行业特定的数据，包括文本、图像、交互记录以及特殊格式的数据（如基因序列）。在训练过程中，模型通常从底层参数开始训练，或者在已有一定能力的通用模型基础上进行进一步训练。这一过程旨在使大模型更好地理解特定领域的术语、知识和工作流程，提高它在行业应用中的性能和准确性，确保其专业性和效率。以谷歌的蛋白质模型AlphaFold2为例，该模型专注于生物信息学领域，在预训练阶段深入分析和学习了大量实验室测定的蛋白质结构数据。这使得模型能够捕捉蛋白质序列与其空间结构之间的复杂关系，从而准确理解和预测蛋白质的复杂三维结构。

预训练方式不仅需要大量的计算资源和长期的训练过程，还需要行业专家的密切合作和深度参与。这种方式通常需要较大的投入，因此目前应用相对较少。此外，从头开始的预训练涉及复杂的数据集准备和模型设计，以及在训练过程中不断进行调优和验证，因此，只有少数企业和科研机构能够承受这种高投入、高风险的方式，尽管其潜在回报同样高。随着技术的进步和成本的降低，未来预训练行业大模型的应用可能会增加。

#### 2.1.2 模型微调

模型微调是基于预训练大模型的一种优化策略，它通过调整模型的某些参数，使其更贴合特定数据集，进而提升在具体业务场景下的表现。这种方法对于性能要求较高的专业领域尤为适用。实际操作中，当一个通用模型难以精确处理或产生专业内容时，模型微调能够增强大模型对行业专有术语的理解，进而提高应用相关知识的能力，确保输出的内容满足特定的业务规范。例如，在零售行业的客服场景中，经过微调的模型能够掌握商品信息并按照企业提供的故障排查流程与用户进行互动。微调完成后，需要对大模型进行测试与评估，根据反馈继续优化性能，并对最终的模型版本进行部署和验证。图2-3展示了模型微调的详细过程。

![image](https://github.com/user-attachments/assets/7ebc7389-2a03-4838-add4-d8449e77482f)


### 图2-3 模型微调过程

|步骤|说明|
| ---- | ---- |
|基础模型|使用已经预训练好的大模型|
|数据集|准备针对特定业务场景的数据集|
|模型微调|调整模型参数以适配特定数据集|
|模型性能优化|根据微调结果优化模型性能|
|测试评估|对微调后的模型进行性能测试和评估|
|部署验证|将优化后的模型进行部署并验证其在实际场景中的效果|

模型微调这一技能将行业知识整合到模型的参数中，使得经过微调的模型不仅保留了其通用的知识结构，还能精确地解读与应用行业有关的特定知识，从而更好地适应多样化应用场景，并针对实际需求提供解决方案。例如，在医疗领域，使用临床数据进行微调的大模型能够更精准地解释医学文献和病历报告，以满足医生辅助诊断的需求。

模型微调是在个性化优化与成本管理之间找到平衡的一种策略。它通常包括调整权重参数或改变模型架构，并且需要通过多次迭代才能达到理想的性能标准。相较于其他不进行微调的模型，经过微调的模型在特定任务上能够展现出更好的性能表现，但同时也需要更多的计算资源和时间投入。随着大模型应用场景的不断细化和专业化，模型微调技术将在提升模型实用性和准确性方面发挥越来越重要的作用。 
